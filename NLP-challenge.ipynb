{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1503fe30",
   "metadata": {},
   "source": [
    "# SQL for AI Projects\n",
    "\n",
    "## Natural Language Processing Challenge\n",
    "\n",
    "In this Jupyter notebook - we'll quickly setup the DuckDB database, get you familiar with this Google Colab setup and then we'll dive into the NLP challenge exercises for the SQL for AI Projects course!\n",
    "\n",
    "### Challenge Exercises\n",
    "\n",
    "1. Explore and transform tourist location site `html_data` column from the `locations` table\n",
    "2. Apply NLP analysis techniques using the `reviews` tables\n",
    "3. Analyze experiment results by joining multiple tables using A/B test framework\n",
    "\n",
    "### Database Setup\n",
    "\n",
    "First things first, let's load up our Python libraries and setup access to our database.\n",
    "\n",
    "Don't worry if you're not familiar with Python - we'll just need to run the very first cell to initialize our SQL instance and there will be clear instructions whenever there is some non-SQL components.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "To execute each cell in this notebook - you can click on the play button on the left of each cell or you could simply hit the `Run all` button on the top of the notebook just below the menu toolbar.\n",
    "\n",
    "This cell below will help us download and connect to a DuckDB database object within this notebook's temporary environment.\n",
    "\n",
    "There will also be a few outputs in the same cell including the following:\n",
    "\n",
    "* An interactive entity relationship diagram for our database is also as an output from the following cell. This will help us visualize all of the database tables and their relevant primary and foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup steps\n",
    "# ====================\n",
    "\n",
    "# These pip install commands are required for Google Collab notebook environment\n",
    "!pip install --upgrade --quiet duckdb==1.3.1\n",
    "!pip install --quiet duckdb-engine==0.17.0\n",
    "!pip install --quiet jupysql==0.11.1\n",
    "\n",
    "# Also need to setup Git LFS for large file dowloads\n",
    "!apt-get install git-lfs -y\n",
    "!git lfs install\n",
    "\n",
    "# Clone GitHub repo into a \"data\" folder\n",
    "!git clone https://github.com/LinkedInLearning/real-world-data-and-AI-challenges-with-SQL-3813163.git data\n",
    "\n",
    "# Need to change directory into \"data\" to run download database object\n",
    "%cd data\n",
    "!git lfs pull\n",
    "\n",
    "# Then we need to change directory back up so all our paths are correct!\n",
    "%cd ..\n",
    "\n",
    "# Time to import all our Python packages\n",
    "import duckdb\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Load the jupysql extension to enable us to run SQL code in code cells\n",
    "%load_ext sql\n",
    "\n",
    "# We can now set some basic Pandas settings for rendering SQL outputs\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "# This is a convenience function to print long strings into multiple lines\n",
    "def wrap_print(text):\n",
    "    print(textwrap.fill(text, width=80))\n",
    "\n",
    "# This is some boilerplate code to help us format printed output with wrapping\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output pre {\n",
    "    white-space: pre-wrap;\n",
    "    word-break: break-word;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# Connecting to DuckDB\n",
    "# ====================\n",
    "\n",
    "# Setup the SQL connection\n",
    "connection = duckdb.connect(\"data/data.db\")\n",
    "%sql connection\n",
    "\n",
    "# Run a few test queries using both connections\n",
    "tables = connection.execute(\"SHOW TABLES\").fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "\n",
    "preview_counts_list = []\n",
    "for table_name in table_names:\n",
    "    try:\n",
    "        preview_counts_list.append(\n",
    "            connection.execute(f\"\"\"\n",
    "                SELECT '{table_name}' AS table_name,\n",
    "                    COUNT(*) AS record_count\n",
    "                FROM {table_name}\"\"\").fetchdf()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not preview table {table_name}: {e}\")\n",
    "        \n",
    "\n",
    "print(\"‚úÖ Database is now ready!\")\n",
    "\n",
    "print(\"\\nüìã Show count of rows from each table in the database:\")\n",
    "\n",
    "# Combine all dataframes in preview_df_list\n",
    "preview_counts_df = pd.concat(preview_counts_list, ignore_index=True)\n",
    "\n",
    "display(preview_counts_df)\n",
    "\n",
    "display(HTML('''\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>\n",
    "'''\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d40c1",
   "metadata": {},
   "source": [
    "# 1. How to Run SQL Queries\n",
    "\n",
    "Let's quickly see how we can run SQL code in our Jupyter notebook.\n",
    "\n",
    "In our Colab environment we can run single or multi-line queries. We can also easily save the output of SQL queries as a local Pandas DataFrame object and even run subsequent SQL queries which can interact with these same DataFrame objects.\n",
    "\n",
    "## 1.1 Single Line SQL Query\n",
    "\n",
    "We can use our notebook magic `%sql` at the start of a notebook cell to run a single line of SQL to query our database.\n",
    "\n",
    "Let's take a look at the first 5 rows from the `locations` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25719458",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28416b",
   "metadata": {},
   "source": [
    "## 1.2 Multi-Line SQL Query\n",
    "\n",
    "We can also run multi-line SQL queries by using a different notebook magic `%%sql` where we now have 2 percentage signs.\n",
    "\n",
    "We'll apply a filter on our `location` dataset and return 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cf549",
   "metadata": {},
   "source": [
    "## 1.3 Saving SQL Outputs\n",
    "\n",
    "By using the `<<` operator, we can assign the result of a SQL query (returned as a Pandas DataFrame) to a named Python variable in the notebook‚Äôs scope.\n",
    "\n",
    "### 1.3.1 Single Line Assignment\n",
    "\n",
    "We can specify the name of the output variable directly after the `%sql` or `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36119368",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql single_magic_df << SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91656938",
   "metadata": {},
   "source": [
    "We can now reference the Python variable directly as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python notebook scope\n",
    "single_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc8169",
   "metadata": {},
   "source": [
    "We can also use this same variable as a table reference within a DuckDB `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM single_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fc9bb",
   "metadata": {},
   "source": [
    "### 1.3.2 Multi-line Assignment\n",
    "\n",
    "This assignment using `<<` also works with the `%%sql` (multi-line) magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ba366",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql multi_magic_df <<\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad734fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f452d",
   "metadata": {},
   "source": [
    "When referencing the Python variable within DuckDB, we can also use it inside a multi-line SQL query using the `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05992467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM multi_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebe3cc",
   "metadata": {},
   "source": [
    "# 2. Challenge Exercise #1\n",
    "\n",
    "In this exercise, we‚Äôll clean and prepare the html_data column from the locations table so it‚Äôs ready for NLP.\n",
    "\n",
    "## 2.1 Inspect Raw Data\n",
    "\n",
    "Let‚Äôs start by looking at a single row ‚Äî specifically for Yosemite National Park ‚Äî to see what kind of cleaning is needed.\n",
    "\n",
    "We‚Äôll use the .loc method in Pandas to inspect the raw HTML. In this case, our expression:\n",
    "\n",
    "```python\n",
    "yosemite_html_example_df.loc[0, \"html_data\"]\n",
    "```\n",
    "\n",
    "Means: ‚ÄúGet the value from the first row of the DataFrame, specifically from the html_data column.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql yosemite_html_example_df << SELECT html_data FROM locations WHERE location_id = 1;\n",
    "\n",
    "# We'll save this variable for use in a later cell!\n",
    "yosemite_raw_html_string = yosemite_html_example_df.loc[0, \"html_data\"]\n",
    "\n",
    "print(yosemite_raw_html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc499313",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
