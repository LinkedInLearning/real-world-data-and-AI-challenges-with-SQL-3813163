{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1503fe30",
   "metadata": {},
   "source": [
    "# SQL for AI Projects - Natural Language Processing\n",
    "\n",
    "In this Jupyter notebook - we'll quickly setup the DuckDB database environment and we'll dive into the natural language processing challenge exercises for the SQL for AI Projects course!\n",
    "\n",
    "## Challenge Exercises\n",
    "\n",
    "1. Explore and transform tourist location site `html_data` column from the `locations` table\n",
    "2. Apply NLP analysis techniques using the `reviews` tables\n",
    "3. Analyze experiment results by joining multiple tables using A/B test framework\n",
    "\n",
    "## Database Setup\n",
    "\n",
    "First things first, let's load up our Python libraries and setup access to our database.\n",
    "\n",
    "Don't worry if you're not familiar with Python - we'll just need to run the very first cell to initialize our SQL instance and there will be clear instructions whenever there is some non-SQL components.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "To execute each cell in this notebook - you can click on the play button on the left of each cell or you could simply hit the `Run all` button on the top of the notebook just below the menu toolbar.\n",
    "\n",
    "This cell below will help us download and connect to a DuckDB database object within this notebook's temporary environment.\n",
    "\n",
    "There will also be a few outputs in the same cell including the following:\n",
    "\n",
    "* An interactive entity relationship diagram for our database is also as an output from the following cell. This will help us visualize all of the database tables and their relevant primary and foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f2cd2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# These pip install commands are required for Google Collab notebook environment\n",
    "!pip install --upgrade --quiet duckdb==1.3.1\n",
    "!pip install --quiet duckdb-engine==0.17.0\n",
    "!pip install --quiet jupysql==0.11.1\n",
    "\n",
    "# Also need to setup Git LFS for large file dowloads\n",
    "!apt-get install git-lfs -y\n",
    "!git lfs install\n",
    "\n",
    "# Clone GitHub repo into a \"data\" folder\n",
    "!git clone https://github.com/LinkedInLearning/real-world-data-and-AI-challenges-with-SQL-3813163.git data\n",
    "\n",
    "# Need to change directory into \"data\" to run download database object\n",
    "%cd data\n",
    "!git lfs pull\n",
    "\n",
    "# Then we need to change directory back up so all our paths are correct!\n",
    "%cd ..\n",
    "\n",
    "import duckdb\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Load the jupysql extension to run SQL code in code cells\n",
    "%load_ext sql\n",
    "\n",
    "# We can now set some basic Pandas settings for rendering SQL outputs\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "# This is a convenience function to print long strings into multiple lines\n",
    "def wrap_print(text):\n",
    "    print(textwrap.fill(text, width=80))\n",
    "\n",
    "# This is some boilerplate code to help us format printed output with wrapping\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output pre {\n",
    "    white-space: pre-wrap;\n",
    "    word-break: break-word;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# Connecting to DuckDB\n",
    "# ====================\n",
    "\n",
    "# Setup the SQL connection\n",
    "connection = duckdb.connect(\"data/data.db\")\n",
    "%sql connection\n",
    "\n",
    "# Run a few test queries using both connections\n",
    "tables = connection.execute(\"SHOW TABLES\").fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "\n",
    "preview_counts_list = []\n",
    "for table_name in table_names:\n",
    "    try:\n",
    "        preview_counts_list.append(\n",
    "            connection.execute(f\"\"\"\n",
    "                SELECT '{table_name}' AS table_name,\n",
    "                    COUNT(*) AS record_count\n",
    "                FROM {table_name}\"\"\").fetchdf()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not preview table {table_name}: {e}\")\n",
    "        \n",
    "\n",
    "print(\"‚úÖ Database is now ready!\")\n",
    "\n",
    "print(\"\\nüìã Show count of rows from each table in the database:\")\n",
    "\n",
    "# Combine all dataframes in preview_df_list\n",
    "preview_counts_df = pd.concat(preview_counts_list, ignore_index=True)\n",
    "\n",
    "display(preview_counts_df)\n",
    "\n",
    "display(HTML('''\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>\n",
    "'''\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
