{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1503fe30",
   "metadata": {},
   "source": [
    "# SQL for AI Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11905e5c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Natural Language Processing Challenge**\n",
    "\n",
    "In this Jupyter notebook - we'll quickly setup the DuckDB database, get you familiar with this Google Colab setup and then we'll dive into the NLP challenge exercises for the SQL for AI Projects course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdec9c4",
   "metadata": {},
   "source": [
    "### Challenge Exercises\n",
    "\n",
    "1. Clean webpage text data\n",
    "2. Investigate customer review text\n",
    "3. Implement A/B test framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1772483",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "\n",
    "First things first, let's load up our Python libraries and setup access to our database.\n",
    "\n",
    "Don't worry if you're not familiar with Python - we'll just need to run the very first cell to initialize our SQL instance and there will be clear instructions whenever there is some non-SQL components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cef12",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "To execute each cell in this notebook - you can click on the play button on the left of each cell or you could simply hit the `Run all` button on the top of the notebook just below the menu toolbar.\n",
    "\n",
    "This cell below will help us download and connect to a DuckDB database object within this notebook's temporary environment.\n",
    "\n",
    "There will also be a few outputs in the same cell including the following:\n",
    "\n",
    "* An interactive entity relationship diagram for our database is also as an output from the following cell. This will help us visualize all of the database tables and their relevant primary and foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup steps\n",
    "# ====================\n",
    "\n",
    "# These pip install commands are required for Google Colab notebook environment\n",
    "!pip install --upgrade --quiet duckdb==1.3.1\n",
    "!pip install --quiet duckdb-engine==0.17.0\n",
    "!pip install --quiet jupysql==0.11.1\n",
    "\n",
    "# Also need to setup Git LFS for large file dowloads\n",
    "# This helps us to download large files stored on GitHub\n",
    "!apt-get install git-lfs -y\n",
    "!git lfs install\n",
    "\n",
    "# Clone GitHub repo into a \"data\" folder\n",
    "!git clone https://github.com/LinkedInLearning/real-world-data-and-AI-challenges-with-SQL-3813163.git data\n",
    "\n",
    "# Need to change directory into \"data\" to run download database object\n",
    "%cd data\n",
    "!git lfs pull\n",
    "\n",
    "# Then we need to change directory back up so all our paths are correct!\n",
    "%cd ..\n",
    "\n",
    "# Time to import all our Python packages\n",
    "import duckdb\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Load the jupysql extension to enable us to run SQL code in code cells\n",
    "%load_ext sql\n",
    "\n",
    "# We can now set some basic Pandas settings for rendering SQL outputs\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "# This is a convenience function to print long strings into multiple lines\n",
    "# You'll see this in action later on in our tutorial!\n",
    "def wrap_print(text):\n",
    "    print(textwrap.fill(text, width=80))\n",
    "\n",
    "# This is some boilerplate code to help us format printed output with wrapping\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output pre {\n",
    "    white-space: pre-wrap;\n",
    "    word-break: break-word;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# Connecting to DuckDB\n",
    "# ====================\n",
    "\n",
    "# Setup the SQL connection\n",
    "connection = duckdb.connect(\"data/data.db\")\n",
    "%sql connection\n",
    "\n",
    "# Run a few test queries using both connections\n",
    "tables = connection.execute(\"SHOW TABLES\").fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "\n",
    "preview_counts_list = []\n",
    "for table_name in table_names:\n",
    "    try:\n",
    "        preview_counts_list.append(\n",
    "            connection.execute(f\"\"\"\n",
    "                SELECT '{table_name}' AS table_name,\n",
    "                    COUNT(*) AS record_count\n",
    "                FROM {table_name}\"\"\").fetchdf()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not preview table {table_name}: {e}\")\n",
    "        \n",
    "\n",
    "print(\"‚úÖ Database is now ready!\")\n",
    "\n",
    "print(\"\\nüìã Show count of rows from each table in the database:\")\n",
    "\n",
    "# Combine all dataframes in preview_df_list\n",
    "preview_counts_df = pd.concat(preview_counts_list, ignore_index=True)\n",
    "\n",
    "display(preview_counts_df)\n",
    "\n",
    "display(HTML('''\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>\n",
    "'''\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d40c1",
   "metadata": {},
   "source": [
    "# How to Run SQL Queries\n",
    "\n",
    "Let's quickly see how we can run SQL code in our Jupyter notebook.\n",
    "\n",
    "In our Colab environment we can run single or multi-line queries. We can also easily save the output of SQL queries as a local Pandas DataFrame object and even run subsequent SQL queries which can interact with these same DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d5990",
   "metadata": {},
   "source": [
    "## Single Line SQL Query\n",
    "\n",
    "We can use our notebook magic `%sql` at the start of a notebook cell to run a single line of SQL to query our database.\n",
    "\n",
    "Let's take a look at the first 5 rows from the `locations` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25719458",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28416b",
   "metadata": {},
   "source": [
    "## Multi-Line SQL Query\n",
    "\n",
    "We can also run multi-line SQL queries by using a different notebook magic `%%sql` where we now have 2 percentage signs.\n",
    "\n",
    "We'll apply a filter on our `location` dataset and return 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cf549",
   "metadata": {},
   "source": [
    "## Saving SQL Outputs\n",
    "\n",
    "By using the `<<` operator, we can assign the result of a SQL query (returned as a Pandas DataFrame) to a named Python variable in the notebook‚Äôs scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1c3df",
   "metadata": {},
   "source": [
    "### Single Line Assignment\n",
    "\n",
    "We can specify the name of the output variable directly after the `%sql` or `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36119368",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql single_magic_df << SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91656938",
   "metadata": {},
   "source": [
    "We can now reference the Python variable directly as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python notebook scope\n",
    "single_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc8169",
   "metadata": {},
   "source": [
    "We can also use this same variable as a table reference within a DuckDB `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM single_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fc9bb",
   "metadata": {},
   "source": [
    "### Multi-line Assignment\n",
    "\n",
    "This assignment using `<<` also works with the `%%sql` (multi-line) magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ba366",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql multi_magic_df <<\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad734fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataframe\n",
    "multi_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f452d",
   "metadata": {},
   "source": [
    "When referencing the Python variable within DuckDB, we can also use it inside a multi-line SQL query using the `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05992467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM multi_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebe3cc",
   "metadata": {},
   "source": [
    "# 1. Clean Text Data\n",
    "\n",
    "In this exercise #1 - we‚Äôll clean and prepare the `html_data` column from the locations table so it‚Äôs ready for NLP.\n",
    "\n",
    "Here is an overview of what we will cover in this tutorial:\n",
    "\n",
    "* Deep dive into using `REGEXP_REPLACE`\n",
    "* Remove HTML tags\n",
    "* Clean up newline, whitespace and `&` characters\n",
    "* Apply advanced find-and-replace using `REGEXP_REPLACE`\n",
    "* Maintain original document structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80ab2e",
   "metadata": {},
   "source": [
    "## 1.1 Inspect Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be20d2",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1.2 Viewing Raw HTML\n",
    "\n",
    "Let‚Äôs start by looking at a single row ‚Äî specifically for Yosemite National Park ‚Äî to see what kind of cleaning is needed.\n",
    "\n",
    "We‚Äôll use the `.loc` method in Pandas to inspect the raw HTML. In this case, our expression below is how we would implement - ‚ÄúGet the value from the first row of the DataFrame, specifically from the html_data column.‚Äù\n",
    "\n",
    "```python\n",
    "yosemite_html_example_df.loc[0, \"html_data\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql yosemite_html_example_df << SELECT html_data FROM locations WHERE location_id = 1;\n",
    "\n",
    "# We'll save this variable for use in a later cell\n",
    "yosemite_raw_html_string = yosemite_html_example_df.loc[0, \"html_data\"]\n",
    "\n",
    "print(yosemite_raw_html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc499313",
   "metadata": {},
   "source": [
    "### 1.1.2 Inspect Rendered Data\n",
    "\n",
    "As we can see - there is a lot of cleaning that needs to be done with this!\n",
    "\n",
    "Let's take a look at how we can print out our HTML and see how it would render on an actual webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08188e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(yosemite_raw_html_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cbb776",
   "metadata": {},
   "source": [
    "## 1.2 Removing HTML Tags\n",
    "\n",
    "After inspecting the HTML code and our rendered data above - a simple solution comes to mind - potentially we can remove all the tags to only keep us the main text contents that we would see when we visit the actual web page generated by the HTML code.\n",
    "\n",
    "We can employ some regular expressions - also known as **regex** - and use the `REGEXP_REPLACE` SQL function to help us get this done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222947ed",
   "metadata": {},
   "source": [
    "### 1.2.1 Introduction to `REGEXP_REPLACE`\n",
    "\n",
    "We'll get very familiar with the `REGEXP_REPLACE` function as we'll be using it throughout this tutorial.\n",
    "\n",
    "An example query we will use below is as follows to extract the text data for Yosemite - we'll also store this as a Python variable `yosemite_removed_tags_df` so we can access it again later:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  REGEXP_REPLACE(html_data, '<[^>]+>', '', 'g') AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 1;\n",
    "```\n",
    "\n",
    "Below is a simple breadown of the query components is included here:\n",
    "\n",
    "| Function         | Purpose                                                |\n",
    "| ---------------- | ------------------------------------------------------ |\n",
    "| `REGEXP_REPLACE` | Performs regex-based text replacement                  |\n",
    "| `html_data     ` | The column of string data that we want to adjust       |\n",
    "| `'<[^>]+>'`      | Matches any HTML tag like `<p>`, `<h2>`, `<ul>` etc    |\n",
    "| `[ ... ]`        | Defines a character class to match with inside the [ ] |\n",
    "| `''`             | Replaces matched text with nothing (i.e. deletes them) |\n",
    "| `'g'`            | Global flag ‚Äî apply to all matches, not just the first |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37722c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_removed_tags_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(html_data, '<[^>]+>', '', 'g') AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f56f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yosemite_removed_tags_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434dbc0",
   "metadata": {},
   "source": [
    "## 1.3 Removing Newline Characters\n",
    "\n",
    "It looks like there's a few newline `\\n` characters now appear in our transformed `html_data` string.\n",
    "\n",
    "We can deploy our `REGEXP_REPLACE` function again to make this work to trim our text outputs and remove those newlines from our already transformed `text_data` column.\n",
    "\n",
    "This time - notice how I'm using the `yosemite_removed_tags_df` as the target for my `SELECT` statement in my SQL query below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3488ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_removed_tags_trimmed_df <<\n",
    "SELECT\n",
    "    REGEXP_REPLACE(text_data, '[\\n]', '', 'g') AS text_data\n",
    "FROM yosemite_removed_tags_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yosemite_removed_tags_trimmed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94423ac",
   "metadata": {},
   "source": [
    "### 1.3.1 Pretty Printing Long Strings\n",
    "\n",
    "We can't really see the entire string when we just display it like we have above - so I've implemented a neat printing function which we can use to see our string in a slightly nicer format.\n",
    "\n",
    "The only catch is that we'll need to use our `.loc` notation to extract the text data from our Pandas DataFrame Python variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(yosemite_removed_tags_trimmed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd4445",
   "metadata": {},
   "source": [
    "### 1.3.2 Fixing Our Mistakes\n",
    "\n",
    "Wait a minute...it looks like we have a few more issues!\n",
    "\n",
    "Our `REGEXP_REPLACE` might have removed our additional newline characters but now it looks like we've squished a few of our words together in the raw text data.\n",
    "\n",
    "We can remove these by using our trusty `REGEXP_REPLACE` again - but this time we replace the empty string character with a single whitespace.\n",
    "\n",
    "Let's apply our changes on the same `yosemite_removed_tags_df` Pandas DataFrame we used for our previous SQL query - but we will assign our output to a new variable called `yosemite_removed_tags_and_newlines_df`\n",
    "\n",
    "**Note** - yes, I know the long variable names seem like a pain...but we have a popular saying \"code is usually read many more times than it's written\" so you can think of this as the equivalent of \"a stitch in time, saves nine\" sort of thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_removed_tags_and_newlines_df <<\n",
    "SELECT\n",
    "    # This time swap out the '' character for ' '\n",
    "    REGEXP_REPLACE(text_data, '[\\n]', ' ', 'g') AS text_data\n",
    "FROM yosemite_removed_tags_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(yosemite_removed_tags_and_newlines_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaaf04d",
   "metadata": {},
   "source": [
    "## 1.4 Further Text Cleaning\n",
    "\n",
    "Now we've got more cleaning to do - maybe we'll want to get rid of those pesky little `&amp;` characters and replace them with a single `&` character.\n",
    "\n",
    "We've also got a few too many whitespace characters here in our text.\n",
    "\n",
    "Let's apply our changes one at a time - but at some point we will need to think about how we can combine all of these changes in one go from our source `locations` table instead of applying these transformations one at a time.\n",
    "\n",
    "Let's perform the following transformations:\n",
    "1. Replace `&amp;` with `&`\n",
    "2. Replace one or more whitespace character with a single whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce342108",
   "metadata": {},
   "source": [
    "### 1.4.1 `REGEXP_REPLACE` With Special Characters\n",
    "\n",
    "Sometimes when using `REGEXP_REPLACE` we need to be careful with special characters when we are searching for a specific pattern. Try playing around with the `'&amp;'` below and you'll begin to see what a I mean! If you want to use it with the character class definition square brackets - we'll need to use the backslash character `\\` to escape important characters.\n",
    "\n",
    "Note that these days - it's easy enough to ask an AI to assist with your regular expressions - but back in the old day's we needed to always look these up in Google or use specific Regex checking tools like [\"I Hate Regex\"](https://ihateregex.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1477935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_removed_tags_newlines_ampersand_df <<\n",
    "SELECT\n",
    "    REGEXP_REPLACE(text_data, '&amp;', '&', 'g') AS text_data\n",
    "FROM yosemite_removed_tags_and_newlines_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7baf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(yosemite_removed_tags_newlines_ampersand_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9217c",
   "metadata": {},
   "source": [
    "### 1.4.2 Regular Expression Character Class\n",
    "\n",
    "We can also use our character classes `[ ]+` to let our `REGEXP_REPLACE` to find and replace 1 or more whitespace characters in a row with a single whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10422ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_removed_tags_newlines_ampersand_spaces_df <<\n",
    "SELECT\n",
    "    # We can use [ ]+ to represent 1 or more spaces\n",
    "    REGEXP_REPLACE(text_data, '[ ]+', ' ', 'g') AS text_data\n",
    "FROM yosemite_removed_tags_newlines_ampersand_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(yosemite_removed_tags_newlines_ampersand_spaces_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa527a7a",
   "metadata": {},
   "source": [
    "## 1.5 Combining Transformations\n",
    "\n",
    "So let's say we want to apply all of our changes that we've identified so far in one-shot from the raw `locations` table within our database.\n",
    "\n",
    "We have the following transformations to apply:\n",
    "\n",
    "1. Remove HTML tags\n",
    "2. Replace multiple newline characters with a single space\n",
    "3. Replace funny ampersand `&amp;` characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47573c17",
   "metadata": {},
   "source": [
    "### 1.5.1 Nested `REGEXP_REPLACE`\n",
    "\n",
    "We can again complete this task using our trust `REGEXP_REPLACE` function!\n",
    "\n",
    "The only catch here is that we'll need to use our function in a \"nested\" form to apply these changes one after another - and we'll need to think about the order of how we apply our changes.\n",
    "\n",
    "One approach I use to better understand the \"nesting\" behaviour is to always work from **inside-out** - the SQL engine will start from the most nested transformation first before applying the outer nested function.\n",
    "\n",
    "Let's give this a shot below and store our results into a variable called `yosemite_one_shot_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17007010",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql yosemite_one_shot_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "        # 1. Most inner function for tag cleanup\n",
    "        REGEXP_REPLACE(html_data, '<[^>]+>', '', 'g'),\n",
    "        # 2. Now we can clean up newline and all whitespace in one-shot\n",
    "        # We also remove any \\r returns and \\t tab characters\n",
    "        '[\\n\\r\\t\\ ]+', ' ', 'g'\n",
    "    ),\n",
    "    # 3. Now we can apply our & update\n",
    "    '&amp;', '&', 'g'\n",
    "  )\n",
    "   AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(yosemite_one_shot_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ae878",
   "metadata": {},
   "source": [
    "## 1.6 Testing Another Example\n",
    "\n",
    "We've been performing all our transformations so far on the Yosemite location data - let's take a look at another specific example to challenge our SQL skills and clean our data further!\n",
    "\n",
    "`location_id = 46` contains the LACMA Los Angeles County Museum of Art details.\n",
    "\n",
    "This will be a good example for us to implement even further data cleansing steps.\n",
    "\n",
    "Let's firstly print out our example record to see what we're playing with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76563748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql museum_html_example_df << SELECT html_data FROM locations WHERE location_id = 46;\n",
    "\n",
    "# We'll save this variable for use in a later cell\n",
    "museum_raw_html_string = museum_html_example_df.loc[0, \"html_data\"]\n",
    "\n",
    "print(museum_raw_html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4241f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(museum_raw_html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(museum_raw_html_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabebc5",
   "metadata": {},
   "source": [
    "### 1.6.1 Removing Brackets\n",
    "\n",
    "One of the first things I've noticed here is that we'll likely end up with the round brackets or paranethesis around the `(Los Angeles County Museum of Art)`\n",
    "\n",
    "We can aim to try and remove these brackets and also apply the same exact transformations we've seen with our Yosemite example.\n",
    "\n",
    "Let's try this first to see if we need to apply further transforms.\n",
    "\n",
    "We can use our trusty `REGEXP_REPLACE` to remove both the left and right paranthesis characters - however we'll need to be careful with how we apply the backslash `\\` to escape these special regular expression chraracters in our function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql museum_transformed_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "        # 1. Most inner function for tag cleanup\n",
    "        REGEXP_REPLACE(html_data, '<[^>]+>', '', 'g'),\n",
    "        # 2. Now we can clean up newline and all whitespace in one-shot\n",
    "        # Here we can also add in our \\( and \\) escaped paranetheses characters\n",
    "        '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "    ),\n",
    "    # 3. Now we can apply our & update\n",
    "    '&amp;', '&', 'g'\n",
    "  )\n",
    "   AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59965550",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(museum_transformed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f99ef",
   "metadata": {},
   "source": [
    "### 1.6.1 Removing Specific Tags\n",
    "\n",
    "This is ALMOST there - but we have one more complication that we'll need to fix up!\n",
    "\n",
    "The very first line seems to have a repeat in the location name - we can see `LACMA Los Angeles County Museum of Art LACMA Los Angeles County Museum of Art` in our first line of the previous output.\n",
    "\n",
    "We'll need to inspect our raw HTML to see where this comes from - if we inspect the first few rows from our raw HTML that we had previously - we can see both a `title` and level 1 heading `h1` tag that repeats the location name.\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>LACMA (Los Angeles County Museum of Art)</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>LACMA (Los Angeles County Museum of Art)</h1>\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59624b84",
   "metadata": {},
   "source": [
    "### 1.6.2 Common Ordering Mistakes\n",
    "\n",
    "We should be right to also use our `REGEXP_REPLACE` in a nested fashion to remove this additional `title` tag to remove the duplicate in our transformed text output - however we'll need to be careful with the order of which we apply the `REGEXP_REPLACE` transformations.\n",
    "\n",
    "If we were to apply this title tag removal **after** we've already removed **all** of our tags - then nothing would happen!\n",
    "\n",
    "Let's demonstrate this in action before we see how we should fix it - imagine we wanted to apply `<title>` tag removal after all of our original transformations using this regular expression: `(?si)<title>.*?</title>`\n",
    "\n",
    "The breakdown of what's happening in this regular expression is below:\n",
    "\n",
    "* (?si) ‚Äì two inline flags\n",
    "    + s: single‚Äëline mode, so the dot . matches everything, including newlines\n",
    "    + i: case‚Äëinsensitive, so it will match <title>, <Title>, <TITLE>, etc. \n",
    "* <title> ‚Äì literally matches the opening tag that we're after\n",
    "* `.*?` ‚Äì a non‚Äëgreedy match of any characters from just after <title> to the earliest possible </title>\n",
    "* </title> ‚Äì literally matches the closing `</title> tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql museum_transformed_removed_title_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        # 1. Most inner function for tag cleanup\n",
    "        REGEXP_REPLACE(html_data, '<[^>]+>', '', 'g'),\n",
    "        # 2. Now we can clean up newline and all whitespace in one-shot\n",
    "        # Here we can also add in our \\( and \\) escaped paranetheses characters\n",
    "        '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "      ),\n",
    "      # 3. Now we can apply our & update\n",
    "      '&amp;', '&', 'g'\n",
    "    ),\n",
    "    # 4. Let's say we put in our <title> removal here...\n",
    "    '(?si)<title>.*?</title>', '', 'g'\n",
    "  ) AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2989560",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(museum_transformed_removed_title_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954cfa8",
   "metadata": {},
   "source": [
    "### 1.6.2 Fixing Up The Order\n",
    "\n",
    "We can still see the repetition right at the beginning of our text!\n",
    "\n",
    "This is because when we apply the `REGEXP_REPLACE` to remove our HTML tags - we inadvertantly also remove the `<title>` tags we are looking to replace so our follow-up `REGEXP_REPLACE` call doesn't see the data.\n",
    "\n",
    "Let's try this again - but we'll adjust the order of our replacements a little and store our outputs in `museum_transformed_removed_title_adjusted_order_df` (I know...the names are getting a bit long right?!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql museum_transformed_removed_title_adjusted_order_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        # 1. Let's say we put in our <title> removal here this time!\n",
    "        REGEXP_REPLACE(html_data, '(?si)<title>.*?</title>', '', 'g'),\n",
    "        # 2. Now we can remove all of our tags\n",
    "        '<[^>]+>', '', 'g'\n",
    "      ),\n",
    "      # 3. Now we can clean up newline and all whitespace in one-shot\n",
    "      # Here we can also add in our \\( and \\) escaped paranetheses characters\n",
    "      '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "    ),\n",
    "    # 4. Finally we can remove the ampersand and we're done!\n",
    "    '&amp;', '&', 'g'\n",
    "  ) AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(museum_transformed_removed_title_adjusted_order_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2e8af",
   "metadata": {},
   "source": [
    "## 1.7 Retaining Document Structure\n",
    "\n",
    "Excellent - we've managed to remove the repetition at the beginning of our museum example!\n",
    "\n",
    "But there's more we can do!\n",
    "\n",
    "For traditional NLP - this is probably good enough, we have extracted the raw text and cleaned up most of our tags, additional spaces and fixed the ampersand web-escaped characters.\n",
    "\n",
    "However - for modern LLMs we can take it further and attempt to retain as much of our original document structure as possible. We can do this by further manipulating our raw text into discrete sections.\n",
    "\n",
    "For this exercise - we will need to really inspect our raw HTML to see how we might apply a good generalized rule and apply it across all our documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11c39c",
   "metadata": {},
   "source": [
    "### 1.7.1 Identifying What to Retain\n",
    "\n",
    "If we dive into our raw HTML - we'll be able to see how our level 2 headings might be useful to structure our cleaned text output.\n",
    "\n",
    "These `<h2> ... </h2>` tags can be used with our `REGEXP_REPLACE` to help retain the structure of the document.\n",
    "\n",
    "```html\n",
    "<h2>Summary</h2>\n",
    "<p>The largest art museum in the western United States, with a collection of nearly 150,000 works spanning the history of art from ancient times to the present.</p>\n",
    "</section>\n",
    "<section id=\"best-time\">\n",
    "<h2>Best Time to Visit</h2>\n",
    "<p>Spring and fall usually offer mild weather and smaller crowds. Always check local conditions, as climate can vary by elevation.</p>\n",
    "</section>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe5c48",
   "metadata": {},
   "source": [
    "### 1.7.2 Advanced Find and Replace\n",
    "\n",
    "For our exercise - let's surround whatever contents are inside the H2 heading with a single pipe character. \n",
    "\n",
    "It's a good idea to surround the level 2 contents with a pipe characters `|` before and after the heading text.\n",
    "\n",
    "We can accomplish this find and replace task using the same `REGEXP_REPLACE` function but this time with a slightly different variation using variable substitution!\n",
    "\n",
    "We can use the regular expression: `'<h2>|</h2>'` to replace any occurences of `<h2>` or `</h2>` within the `REGEXP_REPLACE` command.\n",
    "\n",
    "```sql\n",
    "REGEXP_REPLACE(html_data, '(?si)<h2>(.*?)</h2>', '| \\1 |', 'g')\n",
    "```\n",
    "\n",
    "Here is a simple breakdown of this regular expression function:\n",
    "\n",
    "\n",
    "| Component         | Purpose                                                      |\n",
    "| ----------------- | ------------------------------------------------------------ |\n",
    "| `(?si)`           | Matches across multiple lines and is case-insensitive        |\n",
    "| `<h2>`            | Matches the literal opening tag `<h2>`                       |\n",
    "| `(.*?)`           | Capturing group that contains any character between the tags |\n",
    "| `</h2>`           | Matches the literal closing of the tag `</h2>`               |\n",
    "| `'| \\1 |'`        | A backreference to the first (and only) capturing group      |\n",
    "| `'g'`             |  Global flag ‚Äî apply to all matches, not just the first      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7400647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql museum_further_transformed_df <<\n",
    "SELECT\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          # 1. remove title tag contents\n",
    "          REGEXP_REPLACE(html_data, '(?si)<title>.*?</title>', '', 'g'),\n",
    "          # 2. surround level 2 contents with | characters\n",
    "          '(?si)<h2>(.*?)</h2>', '| \\1 |', 'g'\n",
    "        ),\n",
    "        # 3. clean up - remove all other tags\n",
    "        '<[^>]+>', '', 'g'\n",
    "      ),\n",
    "      # 4. further clean up of whitespace and newlines\n",
    "      '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "    ),\n",
    "    # 5. Finally we can remove the ampersand and we're done!\n",
    "    '&amp;', '&', 'g'\n",
    "  ) AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a619e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(museum_further_transformed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec714d46",
   "metadata": {},
   "source": [
    "### 1.7.3 Remove Arbitrary Text\n",
    "\n",
    "This is very close to perfect - but I've noticed one more step we can take to further clean up our output!\n",
    "\n",
    "If we look at the end of our text data output - we can see that our ending of the `text_data` field ends with the following:\n",
    "\n",
    "```text\n",
    "| Useful Links | View on Google Maps Wikipedia Article\n",
    "```\n",
    "\n",
    "It seems that our hyperlink information is removed due to our previous regular expression removing all of the HTML tags. \n",
    "\n",
    "We can apply another `REGEXP_REPLACE` at the end of our series of transformations to remove everything from `Useful Links` to the end of the string.\n",
    "\n",
    "I've also noticed an additional single whitespace character at the beginning of our text-string - so let's also apply a simple `TRIM` function to strip out all leading and trailing whitespace characters also.\n",
    "\n",
    "This will be our final transformation - so let's store our outputs as the variable `museum_final_transformed_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql museum_final_transformed_df <<\n",
    "SELECT\n",
    "  TRIM(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              # 1. remove title tag contents\n",
    "              REGEXP_REPLACE(html_data, '(?si)<title>.*?</title>', '', 'g'),\n",
    "              # 2. surround level 2 contents with | characters\n",
    "              '(?si)<h2>(.*?)</h2>', '| \\1 |', 'g'\n",
    "            ),\n",
    "            # 3. clean up - remove all other tags\n",
    "            '<[^>]+>', '', 'g'\n",
    "          ),\n",
    "          # 4. further clean up of whitespace and newlines\n",
    "          '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "        ),\n",
    "        # 5. We can remove the ampersand\n",
    "        '&amp;', '&', 'g'\n",
    "      ),\n",
    "      # 6. Finally remove the final useful links / wiki missing links\n",
    "      # We'll need to escape the pipe character as it's special!\n",
    "      # The $ denotes the end of the line so we remove everything from | Useful...\n",
    "      '\\| Useful Links.*$', '', 'g'\n",
    "    )\n",
    "  ) AS text_data\n",
    "FROM locations\n",
    "WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_print(museum_final_transformed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ad93d",
   "metadata": {},
   "source": [
    "## 1.8 Apply Transformations to Entire Dataset\n",
    "\n",
    "This is perfect! Let's now remove our `WHERE` filter and apply this to our entire dataset and we're done for exercise 1!\n",
    "\n",
    "We can store our outputs as `locations_transformed_df` and we can quickly check that our transformations look alright for the previous records we were checking `location_id = 1` and `location_id = 46` for our Yosemite and Museum examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093404ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql locations_transformed_df <<\n",
    "SELECT\n",
    "  # we can keep all of our existing locations data here in our final dataset\n",
    "  locations.*,\n",
    "  TRIM(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              # 1. remove title tag contents\n",
    "              REGEXP_REPLACE(html_data, '(?si)<title>.*?</title>', '', 'g'),\n",
    "              # 2. surround level 2 contents with | characters\n",
    "              '(?si)<h2>(.*?)</h2>', '| \\1 |', 'g'\n",
    "            ),\n",
    "            # 3. clean up - remove all other tags\n",
    "            '<[^>]+>', '', 'g'\n",
    "          ),\n",
    "          # 4. further clean up of whitespace and newlines\n",
    "          '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "        ),\n",
    "        # 5. We can remove the ampersand\n",
    "        '&amp;', '&', 'g'\n",
    "      ),\n",
    "      # 6. Finally remove the final useful links / wiki missing links\n",
    "      # We'll need to escape the pipe character as it's special!\n",
    "      # The $ denotes the end of the line so we remove everything from | Useful...\n",
    "      '\\| Useful Links.*$', '', 'g'\n",
    "    )\n",
    "  ) AS text_data\n",
    "FROM locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out our work!\n",
    "locations_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Yosemite which is our first row\n",
    "# Pandas DataFrames are 0-indexed so the first record is the 0th row\n",
    "wrap_print(locations_transformed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Museum example which is our 46th row - index should be 45\n",
    "wrap_print(locations_transformed_df.loc[45, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c2775",
   "metadata": {},
   "source": [
    "# 2. Customer Reviews\n",
    "\n",
    "In this part of our tutorial we'll implement some basic NLP techniques using SQL on our customer reviews dataset.\n",
    "\n",
    "The following NLP techniques will be covered:\n",
    "\n",
    "* Remove stopwords\n",
    "* Bag of Words\n",
    "* Term Frequency\n",
    "* Document Frequency\n",
    "* TF-IDF\n",
    "\n",
    "We'll also use our TF-IDF outputs to answer some simple questions about our user reviews for each tour product.\n",
    "\n",
    "These exercises aim to help you build this skeptical and curious mindset when it comes to preparing data for AI and machine learning tasks!\n",
    "\n",
    "**Note:** in practice - we'll routinely use Python for these NLP transformations, however it's still a great exercise to execute a similar process using SQL only.\n",
    "\n",
    "Currently in `DuckDB` there is no direct natural language processing functions - so we have a perfect challenge to implement some simple traditional NLP techniques using SQL only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfe53c",
   "metadata": {},
   "source": [
    "## 2.1 Inspect Reviews Data\n",
    "\n",
    "Let's first start with by inspecting our `reviews` table to see what data we have available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM reviews LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95553956",
   "metadata": {},
   "source": [
    "## 2.2 Stopwords Removal\n",
    "\n",
    "Our first stop is to apply stop-word removal - this involves identifying and removing words which commonly appear in English documents.\n",
    "\n",
    "The purpose for this removal step is to help remove noise from our dataset - in turn helping our machine learning algorithms to better learn the correct representations within the data inputs.\n",
    "\n",
    "However - we will see from our reviews example that just because it's a standard process doesn't always mean that it's the right solution for every problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f5cc3",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1 Identifying Stopwords\n",
    "\n",
    "Normally in a Python based workflow - stop-word removal is accomplished using standard NLP library functions, however we don't have this luxury in most SQL databases including `DuckDB`.\n",
    "\n",
    "Luckily we can use our trusty `REGEXP_REPLACE` function to easily remove this huge list of English stop-words from our text data - these stop-words below are from the standard Python NLP library called `nltk`:\n",
    "\n",
    "```text\n",
    "a             about         above         after         again         ain  \n",
    "all           am            an            and           any           are  \n",
    "aren't        as            at            be            because       been  \n",
    "before        being         below         between       both          but  \n",
    "by            can           couldn        couldn't      d             did  \n",
    "didn't        didn          do            does          doesn't       doesn  \n",
    "doing         don't         don           down          during        each  \n",
    "few           for           from          further       had           hadn't  \n",
    "hadn          has           hasn't        hasn          have          haven't  \n",
    "haven         having        he            her           here          hers  \n",
    "herself       him           himself       his           how           i  \n",
    "if            in            into          is            isn't         isn  \n",
    "it            it's          its           itself        let's         ll  \n",
    "m             ma            me            mightn        mightn't      more  \n",
    "most          mustn         mustn't       my            myself        needn  \n",
    "needn't       no            nor           not           now           o  \n",
    "of            off           on            once          only          or  \n",
    "other         our           ours          ourselves     out           over  \n",
    "own           re            s             same          shan't        shan  \n",
    "she           she's         should        should've     shouldn't     shouldn  \n",
    "so            some          such          t             than          that  \n",
    "that'll       the           their         theirs        them          themselves  \n",
    "then          there         these         they          this          those  \n",
    "through       to            too           under         until         up  \n",
    "very          was           wasn't        wasn          we            were  \n",
    "weren't       weren         what          when          where         which  \n",
    "while         who           whom          why           will          with  \n",
    "won't         won           wouldn        wouldn't      y             you  \n",
    "you'd         you'll        you're        you've        your          yours  \n",
    "yourself      yourselves\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e6364",
   "metadata": {},
   "source": [
    "### 2.2.1 Implementing Stopword Removal\n",
    "\n",
    "We can implement our stopwords removal this using a simple `REGEXP_REPLACE` function and a very, very, very, very long `OR` conditional expression.\n",
    "\n",
    "Luckily for us - we can generate this regular expression using our favourite AI helper of choice, in fact - I used ChatGPT for mine!\n",
    "\n",
    "Once the replacement is done - it's also common practice to \"collapse\" our final transformed text string by replacing multiple whitespace characters with a single one - this is due to the removal of words using word boundaries within the regular expression. We have seen a similar example in the `locations` HTML data that we manipulated in an earlier exercise.\n",
    "\n",
    "We will also use the global case-insensitive match condition in our `REGEXP_REPLACE` - this makes sure we capture all of the occurences of these stopwords and we won't need to worry about case sensitivity. This option is important as we want all stop words to be removed regardless of whether they are capitalised or not.\n",
    "\n",
    "Finally we apply a `LOWER` transformation on our `text_data` column to prepare ourselves for the next NLP analysis steps.\n",
    "\n",
    "Some traditional NLP techniques perform better with all lowercase text vs mixed case due to lower chance of sparsity (uncommon values) - however some modern NLP techniques like named entity recognition, Q&A parsing and or any application that uses transfomers such as some embedding models like BERT.\n",
    "\n",
    "**To summarize our tasks in the following SQL script**\n",
    "\n",
    "1. Remove stopwords using `REGEXP_REPLACE`\n",
    "2. Collapse multiple whitespaces into a single space\n",
    "3. Lowercase the reviews text\n",
    "4. Apply a trim to remove leading/trailing whitespace\n",
    "\n",
    "Note some of the comments in the below SQL cell for more details - we'll be storing our outputs in a Pandas DataFrame variable called `reviews_stop_words_removed_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_stop_words_removed_df <<\n",
    "SELECT\n",
    "    review_id,\n",
    "    # Keep these columns for analysis later!\n",
    "    product_id,\n",
    "    sentiment,\n",
    "    star_rating,\n",
    "    # Keep the original review text so we can compare\n",
    "    review_text,\n",
    "    # Apply lowercase\n",
    "    TRIM(LOWER(\n",
    "        REGEXP_REPLACE(\n",
    "            # Remove stop-words\n",
    "            REGEXP_REPLACE(\n",
    "                review_text,\n",
    "                '\\b(i|me|my|myself|we|our|ours|ourselves|you|you''re|you''ve|you''ll|you''d|your|yours|yourself|yourselves|he|him|his|himself|she|she''s|her|hers|herself|it|it''s|its|itself|they|them|their|theirs|themselves|what|which|who|whom|this|that|that''ll|these|those|am|is|are|was|were|be|been|being|have|has|had|having|do|does|did|doing|a|an|the|and|but|if|or|because|as|until|while|of|at|by|for|with|about|against|between|into|through|during|before|after|above|below|to|from|up|down|in|out|on|off|over|under|again|further|then|once|here|there|when|where|why|how|all|any|both|each|few|more|most|other|some|such|no|nor|not|only|own|same|so|than|too|very|s|t|can|will|just|don|don''t|should|should''ve|now|d|ll|m|o|re|ve|y|ain|aren|aren''t|couldn|couldn''t|didn|didn''t|doesn|doesn''t|hadn|hadn''t|hasn|hasn''t|haven|haven''t|isn|isn''t|ma|mightn|mightn''t|mustn|mustn''t|needn|needn''t|shan|shan''t|shouldn|shouldn''t|wasn|wasn''t|weren|weren''t|won|won''t|wouldn|wouldn''t)\\b',\n",
    "                '',\n",
    "                'gi'\n",
    "            ),\n",
    "        # Collapse multiple spaces into a single space\n",
    "        '[\\s]+', ' ', 'g'\n",
    "        )\n",
    "    )) AS transformed_review_text\n",
    "FROM reviews;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ba2d0",
   "metadata": {},
   "source": [
    "### 2.2.2 Critically Analyze Reviews\n",
    "\n",
    "Let's now compare the first row with the original and the updated text values to see the stop words removal in action and assess whether it's going to help us with our NLP problem.\n",
    "\n",
    "It's very important to note that while removing stopwords is \"technically\" the correct way to deal with NLP text data - we still need to take a look carefully at our transformations to see if it's actually doing what we're intending!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first row\n",
    "%sql SELECT * FROM reviews_stop_words_removed_df LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original review_text field\n",
    "wrap_print(reviews_stop_words_removed_df.loc[0, \"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e736ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the transformed_review_text field\n",
    "wrap_print(reviews_stop_words_removed_df.loc[0, \"transformed_review_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277fa891",
   "metadata": {},
   "source": [
    "In our case for this single review - we can clearly see that our stop words have been removed and all our terms are now in lowercase - just like we expected...\n",
    "\n",
    "However we can also see that removal of certain stop words totally alters the overall meaning of our review!\n",
    "\n",
    "This is one simple example to demonstrate the importance of checking our data every step of the way - especially when following a \"standardized\" pipeline for NLP machine learning transformations.\n",
    "\n",
    "For our following transformations - we'll actually avoid the stopword removal and process our reviews text as-is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d23dbc",
   "metadata": {},
   "source": [
    "## 2.3 Simple Text Transformations\n",
    "\n",
    "Since we understand now that removing stopwords might actually impact the meaning we can extract from each review - let's still apply some light transformations which will help our NLP techniques.\n",
    "\n",
    "We'll apply the following steps:\n",
    "\n",
    "1. Apply lowercase to all text\n",
    "2. Remove any punctuation (using `REGEXP_REPLACE`)\n",
    "3. Collapse any multiple whitespace characters\n",
    "\n",
    "Let's store our outputs from these transformations in a variable called `transformed_reviews_df` and keep our original columns and add on a `transformed_review_text` field with our changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql transformed_reviews_df <<\n",
    "SELECT\n",
    "  review_id,\n",
    "  product_id,\n",
    "  sentiment,\n",
    "  star_rating,\n",
    "  review_text,\n",
    "  LOWER(\n",
    "    REGEXP_REPLACE(\n",
    "      # Remove punctuation using character class\n",
    "      REGEXP_REPLACE(review_text, '[\\(\\)&,.:;\\\\‚Äî!]', '', 'g'),\n",
    "      # Collapse whitespace\n",
    "      '[ ]+', ' ', 'g'\n",
    "    )\n",
    "  ) AS transformed_review_text\n",
    "FROM reviews;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df22039",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56453f6c",
   "metadata": {},
   "source": [
    "## 2.4 Bag of Words Analysis\n",
    "\n",
    "Let's continue our exercise by implementing a simple bag-of-words transformation on our `transformed_reviews_df` - but first let's step through a single review to understand how we might apply our SQL queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97141e35",
   "metadata": {},
   "source": [
    "### 2.4.1 Analyze Single Review\n",
    "\n",
    "We begin our analysis by looking at an individual review `review_id = '000319b1'`\n",
    "\n",
    "We'll need to use our `.loc` notation and our custom `wrap_print` function to print out both our original and transformed review text for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbee0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql single_review_df << SELECT * FROM transformed_reviews_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7900b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd112505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out original review text\n",
    "wrap_print(single_review_df.loc[0, \"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba521fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out transformed review text\n",
    "wrap_print(single_review_df.loc[0, \"transformed_review_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d1687",
   "metadata": {},
   "source": [
    "### 2.4.2 Implement Tokenization\n",
    "\n",
    "Here's where we start diving into the deep- we'll use some relatively advanced SQL techniques here to convert our text string into a tokenized representation of our reviews data.\n",
    "\n",
    "These techniques really come in handy when dealing with complex data structures within SQL and it was a true threshold concept for me when I was learning in my career!\n",
    "\n",
    "The steps we'll use are as follows:\n",
    "\n",
    "1. Use `REGEXP_SPLIT_TO_ARRAY` to convert our text string into an array of \"terms\"\n",
    "2. Add on an array from 1 to the `ARRAY_LENGTH` of our document to track \"position\"\n",
    "3. Slice our original document array of terms using our \"position\"\n",
    "\n",
    "There's a lot of techniques in the following SQL query so I've tried my best to add comments to make things as clear as possible - please feel free to break up the CTE into multiple steps to understand each transformation step-by-step if you need!\n",
    "\n",
    "Let's also store our outputs as `single_review_tokenized_df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a204e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql single_review_tokenized_df <<\n",
    "WITH cte_arrays AS (\n",
    "SELECT\n",
    "    # 1. Convert our text document into an array\n",
    "    REGEXP_SPLIT_TO_ARRAY(transformed_review_text, '\\s+') AS term_array\n",
    "FROM single_review_df\n",
    "),\n",
    "cte_range AS (\n",
    "SELECT\n",
    "    term_array,\n",
    "    # In DuckDB specifically we need to use the .unnest to get the raw value!\n",
    "    i.unnest AS position\n",
    "FROM cte_arrays\n",
    "# 2. Apply CROSS JOIN UNNEST on our array to get the \"position\" [1, 2, 3 ... N]\n",
    "# Note: we need the +1 here to account for 0 based array indexing with RANGE\n",
    "CROSS JOIN UNNEST(RANGE(1, ARRAY_LENGTH(term_array) + 1)) AS i\n",
    ")\n",
    "SELECT\n",
    "    # Slice out the original term array of our document using the position\n",
    "    term_array[position] AS term,\n",
    "    position\n",
    "FROM cte_range\n",
    "ORDER BY position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_review_tokenized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400ff85",
   "metadata": {},
   "source": [
    "### 2.4.3 Implement Bag-of-Words\n",
    "\n",
    "At this stage - we can simply perform a `GROUP BY COUNT` on our output DataFrame `single_review_tokenized_df` to generate the required output for our Bag of Words analysis.\n",
    "\n",
    "Let's keep our outputs as `single_review_bag_of_words_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79af58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql single_review_bag_of_words_df <<\n",
    "SELECT\n",
    "  term,\n",
    "  COUNT(*) AS frequency\n",
    "FROM single_review_tokenized_df\n",
    "GROUP BY term\n",
    "ORDER BY term;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87282622",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_review_bag_of_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de686ce6",
   "metadata": {},
   "source": [
    "## 2.5 Tokenize All Reviews\n",
    "\n",
    "We can now remove our `WHERE` filter and apply these same tokenization steps we covered on our entire collection of customer reviews.\n",
    "\n",
    "We'll just need to make sure we keep the `review_id` in our query to make sure we keep all of the terms that are related to each document!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee951b9",
   "metadata": {},
   "source": [
    "## 2.5.1 SQL Implementation\n",
    "\n",
    "Let's try this with a very similar SQL query to our previous step but this time we'll use our complete reviews dataset `transformed_reviews_df`.\n",
    "\n",
    "Let's also store our outputs as `reviews_tokenized_df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de324210",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_tokenized_df <<\n",
    "WITH cte_arrays AS (\n",
    "SELECT\n",
    "    review_id,\n",
    "    # 1. Convert our text document into an array\n",
    "    REGEXP_SPLIT_TO_ARRAY(transformed_review_text, '\\s+') AS term_array\n",
    "FROM transformed_reviews_df\n",
    "),\n",
    "cte_range AS (\n",
    "SELECT\n",
    "    review_id,\n",
    "    term_array,\n",
    "    # In DuckDB specifically we need to use the .unnest to get the raw value!\n",
    "    i.unnest AS position\n",
    "FROM cte_arrays\n",
    "# 2. Apply CROSS JOIN UNNEST on our array to get the \"position\" [1, 2, 3 ... N]\n",
    "# Note: we need the +1 here to account for 0 based array indexing with RANGE\n",
    "CROSS JOIN UNNEST(RANGE(1, ARRAY_LENGTH(term_array) + 1)) AS i\n",
    ")\n",
    "SELECT\n",
    "    review_id,\n",
    "    # Slice out the original term array of our document using the position\n",
    "    term_array[position] AS term,\n",
    "    position\n",
    "FROM cte_range\n",
    "ORDER BY review_id, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokenized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566c27f",
   "metadata": {},
   "source": [
    "## 2.6 Bag-of-Words Analysis\n",
    "\n",
    "Let's now extend our Bag-of-Words analysis to the entire range of reviews. For now we will stick with uni-gram terms 1-at-a-time so we can see the logic in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e13c0b",
   "metadata": {},
   "source": [
    "### 2.6.1 Generating Vocabulary\n",
    "\n",
    "Our first challenge for our bag-of-words analysis is to generate what's known as a \"vocabulary\" of all possible terms/tokens which appear in our collection of customer reviews (our corpus).\n",
    "\n",
    "We can simply take a `DISTINCT` of our `term` column in our `reviews_tokenized_df` DataFrame to get our initial uni-gram vocabulary one at a time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT DISTINCT term FROM reviews_tokenized_df ORDER BY term;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5648d",
   "metadata": {},
   "source": [
    "### 2.6.2 Generating Term Frequency & BoW\n",
    "\n",
    "We can now use this same vocabulary logic to generate our final output for the Bag-of-Words uni-gram analysis.\n",
    "\n",
    "We'll need to create a CTE with our previous logic and join onto this to create a simple count of each term within each document. This is also known as the `term frequency`\n",
    "\n",
    "**One key step** here is that we will need to create a complete combination of reviews and terms - before performing a `LEFT JOIN` on our reviews terms using this combination as our \"base\" dataset that is kept on the left side of our join.\n",
    "\n",
    "This ensures that we do not lose any vocabulary terms as we perform the join onto our term frequency counts for each customer review!\n",
    "\n",
    "Let's store our output into the new variable `reviews_unigram_bag_of_words_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_unigram_bag_of_words_df <<\n",
    "WITH cte_vocabulary AS (\n",
    "  SELECT DISTINCT\n",
    "    term\n",
    "  FROM reviews_tokenized_df\n",
    "),\n",
    "cte_reviews AS (\n",
    "  SELECT DISTINCT\n",
    "    review_id\n",
    "  FROM reviews_tokenized_df\n",
    "),\n",
    "# Combine all unique reviews and vocabulary to form our base\n",
    "cte_all_terms_and_reviews_combo AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term\n",
    "  FROM cte_reviews\n",
    "  CROSS JOIN cte_vocabulary\n",
    "),\n",
    "# Technically we calculate the term freq as part of our bag of words analysis!\n",
    "cte_term_frequency AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS frequency\n",
    "  FROM reviews_tokenized_df\n",
    "  GROUP BY review_id, term\n",
    ")\n",
    "# Final bag of words output!\n",
    "SELECT\n",
    "  # we need to use our combo for these columns\n",
    "  combo.review_id,\n",
    "  combo.term,\n",
    "  # we use coalesce here to replace missing values with 0\n",
    "  COALESCE(tf.frequency, 0) AS term_frequency\n",
    "FROM cte_all_terms_and_reviews_combo AS combo\n",
    "LEFT JOIN cte_term_frequency AS tf\n",
    "  ON combo.review_id = tf.review_id\n",
    "  AND combo.term = tf.term\n",
    "# Apply a simple order by review_id and term in alphabetical order\n",
    "ORDER BY combo.review_id, combo.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just take a look at our very first review_id we were inspecting before\n",
    "%sql SELECT * FROM reviews_unigram_bag_of_words_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d688b",
   "metadata": {},
   "source": [
    "## 2.7 Document Frequency\n",
    "\n",
    "Let's use our exact same uni-gram terms to implement `document frequency` which is the count of unique documents or reviews where a specific term appears.\n",
    "\n",
    "We'll need to perform a similar calculation as our `term frequency` but this time instead of using a `GROUP BY COUNT` within each review or document - we will instead apply a `COUNT DISTINCT` on the `review_id` for each uni-gram term.\n",
    "\n",
    "Let's store our output as `reviews_unigram_document_frequency_df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_unigram_document_frequency_df <<\n",
    "WITH cte_document_frequency AS (\n",
    "SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "FROM reviews_tokenized_df\n",
    "GROUP BY term\n",
    "),\n",
    "cte_vocab AS (\n",
    "SELECT DISTINCT\n",
    "    term\n",
    "FROM reviews_tokenized_df\n",
    ")\n",
    "# final output\n",
    "SELECT\n",
    "    vocab.term,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "FROM cte_vocab AS vocab\n",
    "LEFT JOIN cte_document_frequency AS df\n",
    "    ON vocab.term = df.term\n",
    "ORDER BY document_frequency DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b0c80",
   "metadata": {},
   "source": [
    "Let's inspect our `reviews_unigram_document_frequency_df` output DataFrame to see if there are any insights we can extract.\n",
    "\n",
    "Maybe we can take a look at the top 25 terms by document frequency first!\n",
    "\n",
    "Some of these terms might be perfect to apply as stopwords as opposed to our standard list of stopwords from `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21723057",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_unigram_document_frequency_df[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81649f2",
   "metadata": {},
   "source": [
    "## 2.8 TF-IDF Calculation\n",
    "\n",
    "Now let's put together our term frequency and document frequency to generate one of the most common NLP metrics called `TF-IDF` or term frequency inverse document frequency.\n",
    "\n",
    "This helps us generate a metric for each term within each review so we can evaluate the following:\n",
    "\n",
    "1. How common is this term in the current review?\n",
    "2. How rare is this term across all reviews?\n",
    "\n",
    "We'll also need to apply a natural log transformation to our value to scale our final output. This helps us keep our final `TD-IDF` values in the same range of values - however in practice, the ranking of these values are more important than the actual scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dbb4e",
   "metadata": {},
   "source": [
    "### 2.8.1 Uni-gram TF-IDF\n",
    "\n",
    "Let's first try this TF-IDF calculation using our uni-gram terms!\n",
    "\n",
    "We can store our outputs for this transformation as `reviews_unigram_tfidf_df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_unigram_tfidf_df <<\n",
    "# calculate the term frequency\n",
    "WITH cte_term_frequency AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "  FROM reviews_tokenized_df\n",
    "  GROUP BY review_id, term\n",
    "),\n",
    "cte_document_frequency AS (\n",
    "  SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "  FROM reviews_tokenized_df\n",
    "  GROUP BY term\n",
    "),\n",
    "cte_total_document_count AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT review_id) AS document_count\n",
    "  FROM reviews_tokenized_df\n",
    "),\n",
    "cte_combined AS (\n",
    "  # Combine both CTEs to get TF-IDF\n",
    "  SELECT\n",
    "    # we need to use our combo for these columns\n",
    "    tf.review_id,\n",
    "    tf.term,\n",
    "    # we use coalesce here to replace missing values with 0\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    # We use this document count to scale out TF-IDF calculation\n",
    "    docs.document_count\n",
    "  FROM cte_term_frequency AS tf\n",
    "  LEFT JOIN cte_document_frequency AS df\n",
    "    ON tf.term = df.term\n",
    "  CROSS JOIN cte_total_document_count AS docs\n",
    ")\n",
    "# Final output\n",
    "SELECT\n",
    "  review_id,\n",
    "  term,\n",
    "  term_frequency,\n",
    "  document_frequency,\n",
    "  term_frequency * LN(document_count / document_frequency) AS tf_idf\n",
    "FROM cte_combined\n",
    "# Let's order by descending tf_idf within each review ID\n",
    "ORDER BY review_id, tf_idf DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ec0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just take a look at our very first review_id we were inspecting before\n",
    "%sql SELECT * FROM reviews_unigram_tfidf_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6aeb7",
   "metadata": {},
   "source": [
    "### 2.8.2 Bi-gram TF-IDF\n",
    "\n",
    "Sometimes looking at terms/words one-at-a-time only gives us so much information.\n",
    "\n",
    "We might inadvertantly reduce specific terms such as `Los Angeles` or `not great` into their individual uni-gram parts which lowers the contextual information we get from our text data.\n",
    "\n",
    "Let's introduce our `LAG` window function to help us combine our terms based off their positions before we get busy applying our same transformations to calculate `TF-IDF`\n",
    "\n",
    "We can store outputs as `reviews_bigram_tfidf_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_bigram_tfidf_df <<\n",
    "WITH cte_bigrams AS (\n",
    "SELECT\n",
    "    review_id,\n",
    "    # Use LAG window function to take combine 2 positional terms into a bi-gram\n",
    "    LAG(term) OVER (PARTITION BY review_id ORDER BY position) || ' ' || term AS term\n",
    "FROM reviews_tokenized_df\n",
    "),\n",
    "# calculate the term frequency using our cte_bigrams table\n",
    "cte_term_frequency AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "  FROM cte_bigrams\n",
    "  # When we use our window function we also have the last trailing term as NULL\n",
    "  WHERE term IS NOT NULL\n",
    "  GROUP BY review_id, term\n",
    "),\n",
    "# calculate the document frequency using our cte_bigrams table\n",
    "cte_document_frequency AS (\n",
    "  SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "  FROM cte_bigrams\n",
    "  # When we use our window function we also have the last trailing term as NULL\n",
    "  WHERE term IS NOT NULL\n",
    "  GROUP BY term\n",
    "),\n",
    "cte_total_document_count AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT review_id) AS document_count\n",
    "  FROM cte_bigrams\n",
    "),\n",
    "cte_combined AS (\n",
    "  # Combine both CTEs to get TF-IDF\n",
    "  SELECT\n",
    "    # we need to use our combo for these columns\n",
    "    tf.review_id,\n",
    "    tf.term,\n",
    "    # we use coalesce here to replace missing values with 0\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    # We use this document count to scale out TF-IDF calculation\n",
    "    docs.document_count\n",
    "  FROM cte_term_frequency AS tf\n",
    "  LEFT JOIN cte_document_frequency AS df\n",
    "    ON tf.term = df.term\n",
    "  CROSS JOIN cte_total_document_count AS docs\n",
    ")\n",
    "# Final output\n",
    "SELECT\n",
    "  review_id,\n",
    "  term,\n",
    "  term_frequency,\n",
    "  document_frequency,\n",
    "  term_frequency * LN(document_count / document_frequency) AS tf_idf\n",
    "FROM cte_combined\n",
    "# Let's order by descending tf_idf within each review ID\n",
    "ORDER BY review_id, tf_idf DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just take a look at our very first review_id we were inspecting before\n",
    "%sql SELECT * FROM reviews_bigram_tfidf_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75513386",
   "metadata": {},
   "source": [
    "## 2.9 Combining TF-IDF and Products\n",
    "\n",
    "Let's now use our bi-gram TF-IDF dataset `reviews_bigram_tfidf_df` to help us understand how each of our metrics: term frequency, document frequency and `TF-IDF` compare when we start to aggregate these to rank the top words for each `star_rating` for each `product`\n",
    "\n",
    "We'll build upon our work previously and join in more information about our products!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49426721",
   "metadata": {},
   "source": [
    "### 2.9.1 Joining Multiple Tables\n",
    "\n",
    "We'll need to join onto our `reviews` table to make sure we can split out the `star_rating` and also join onto our `products` table in order to get the `product_name` field.\n",
    "\n",
    "Let's revisit our database entity relationship diagram below to reference as we script up our SQL code.\n",
    "\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442006b",
   "metadata": {},
   "source": [
    "### 2.9.2 Product Star Ratings\n",
    "\n",
    "Let's create our joint table `product_star_rating_reviews_df` by averaging up our term frequency, document frequency and TF-IDF by each product and star_rating.\n",
    "\n",
    "We'll also apply some ranking using the `ROW_NUMBER` window function to specify the top few terms for each product and star_rating accordingly.\n",
    "\n",
    "The SQL below is a little bit crazy - but don't worry as this just helps us pull together all of our individual analyses into one single joint table.\n",
    "\n",
    "Let's also store this as `product_star_rating_reviews_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql product_star_rating_reviews_df <<\n",
    "WITH cte_base AS (\n",
    "SELECT\n",
    "    products.product_name,\n",
    "    reviews.star_rating,\n",
    "    tfidf.term,\n",
    "    AVG(tfidf.term_frequency) AS term_frequency,\n",
    "    AVG(tfidf.document_frequency) AS document_frequency,\n",
    "    AVG(tfidf.tf_idf) AS tf_idf\n",
    "FROM reviews_bigram_tfidf_df AS tfidf\n",
    "INNER JOIN reviews\n",
    "    ON tfidf.review_id = reviews.review_id\n",
    "INNER JOIN products\n",
    "    ON reviews.product_id = products.product_id\n",
    "GROUP BY 1,2,3\n",
    "),\n",
    "cte_ranked AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    star_rating,\n",
    "    term,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY term_frequency DESC) AS tf_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY document_frequency DESC) AS df_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY tf_idf DESC) AS tfidf_rank\n",
    "FROM cte_base\n",
    ")\n",
    "# now combine everything into one table using a big self join!\n",
    "SELECT\n",
    "    tf.product_name,\n",
    "    tf.star_rating,\n",
    "    tf.tf_rank AS term_ranking,\n",
    "    tf.term AS tf_term,\n",
    "    df.term AS df_term,\n",
    "    tfidf.term AS tfidf_term\n",
    "FROM cte_ranked AS tf\n",
    "INNER JOIN cte_ranked AS df\n",
    "    ON tf.product_name = df.product_name\n",
    "    AND tf.star_rating = df.star_rating\n",
    "    AND tf.tf_rank = df.df_rank\n",
    "INNER JOIN cte_ranked AS tfidf\n",
    "    ON tf.product_name = tfidf.product_name\n",
    "    AND tf.star_rating = tfidf.star_rating\n",
    "    AND tf.tf_rank = tfidf.tfidf_rank\n",
    "ORDER BY 1,2,3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724452dc",
   "metadata": {},
   "source": [
    "### 2.9.3 California Classic Reviews\n",
    "\n",
    "Let's take a look at a single product and we'll pull out only 1 and 5 star ratings and compare the top 10 terms by each of our metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dff5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM product_star_rating_reviews_df\n",
    "WHERE product_name = 'California Classics'\n",
    "AND star_rating IN (1, 5)\n",
    "AND term_ranking <= 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1343fd",
   "metadata": {},
   "source": [
    "### 2.9.4 Analyzing California Classics Reviews\n",
    "\n",
    "Here we can see that the `term frequency` and `document frequency` terms seem to line up with what we are expecting.\n",
    "\n",
    "Negative ratings seem to state a few things that weren't liked in the term frequency - while the document frequency paints a very clear picture of negative sentiment.\n",
    "\n",
    "\n",
    "However - when we look at the `TF-IDF` terms - we can notice that these are actually the same!\n",
    "\n",
    "These terms although they are high scoring in TF-IDF across the entire corpus or collection of documents. Maybe we don't have enough information when it comes to discriminating just within individual product reviews.\n",
    "\n",
    "In our example - it looks like all relevant top terms are unique to this California Classics tour product but when we zoom into our product - the TF-IDF top terms also come short in regards to insightful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c4f22",
   "metadata": {},
   "source": [
    "## 2.10 Product Specific TF-IDF Metrics\n",
    "\n",
    "Let's now extend our analysis even further and we will group together only our documents for `California Classics` product reviews.\n",
    "\n",
    "This should solve the problem we were facing when identifying relevant TF-IDF terms for one specific product!\n",
    "\n",
    "This query below is going to a little long-winded but it's just a combination of a few steps that we've covered above all put into a single long series of CTEs. The only difference is that we'll need to join onto our `reviews` and `products` table early on to filter out only product reviews for our California Classics tour product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql cali_classics_analysis_df <<\n",
    "WITH cte_bigrams AS (\n",
    "SELECT\n",
    "    tokens.review_id,\n",
    "    # Use LAG window function to take combine 2 positional terms into a bi-gram\n",
    "    LAG(tokens.term) OVER (PARTITION BY tokens.review_id ORDER BY tokens.position) || ' ' || term AS term\n",
    "FROM reviews_tokenized_df AS tokens\n",
    "INNER JOIN reviews\n",
    "    ON tokens.review_id = reviews.review_id\n",
    "INNER JOIN products\n",
    "    ON reviews.product_id = products.product_id\n",
    "WHERE products.product_name = 'California Classics'\n",
    "),\n",
    "cte_tf AS (\n",
    "SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "FROM cte_bigrams\n",
    "# Apply a WHERE filter to remove the first bi-gram which will be NULL\n",
    "WHERE term IS NOT NULL\n",
    "GROUP BY\n",
    "    review_id,\n",
    "    term\n",
    "),\n",
    "cte_df AS (\n",
    "SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "FROM cte_bigrams\n",
    "# Apply a WHERE filter to remove the first bi-gram which will be NULL\n",
    "WHERE term IS NOT NULL\n",
    "GROUP BY\n",
    "    term\n",
    "),\n",
    "cte_doc_count AS (\n",
    "SELECT COUNT(DISTINCT review_id) AS document_count FROM cte_bigrams\n",
    "),\n",
    "cte_vocab AS (\n",
    "SELECT DISTINCT\n",
    "    term\n",
    "FROM cte_df\n",
    "),\n",
    "cte_combined AS (\n",
    "SELECT\n",
    "    tf.review_id,\n",
    "    vocab.term,\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    docs.document_count\n",
    "FROM cte_vocab AS vocab\n",
    "LEFT JOIN cte_tf AS tf\n",
    "    ON vocab.term = tf.term\n",
    "LEFT JOIN cte_df AS df\n",
    "    ON vocab.term = df.term\n",
    "CROSS JOIN cte_doc_count AS docs\n",
    "),\n",
    "cte_nlp_metrics AS (\n",
    "SELECT\n",
    "    nlp.review_id,\n",
    "    reviews.star_rating,\n",
    "    nlp.term,\n",
    "    nlp.term_frequency,\n",
    "    nlp.document_frequency,\n",
    "    nlp.term_frequency * LN(nlp.document_count / nlp.document_frequency) AS tf_idf\n",
    "FROM cte_combined AS nlp\n",
    "INNER JOIN reviews\n",
    "    ON nlp.review_id = reviews.review_id\n",
    "),\n",
    "cte_rating_metrics AS (\n",
    "SELECT\n",
    "    star_rating,\n",
    "    term,\n",
    "    AVG(term_frequency) AS term_frequency,\n",
    "    AVG(document_frequency) AS document_frequency,\n",
    "    AVG(tf_idf) AS tf_idf\n",
    "FROM cte_nlp_metrics AS tfidf\n",
    "GROUP BY\n",
    "    star_rating,\n",
    "    term\n",
    "),\n",
    "cte_ranked AS (\n",
    "SELECT\n",
    "    star_rating,\n",
    "    term,\n",
    "    ROW_NUMBER() OVER (PARTITION BY star_rating ORDER BY term_frequency DESC) AS tf_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY star_rating ORDER BY document_frequency DESC) AS df_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY star_rating ORDER BY tf_idf DESC) AS tfidf_rank\n",
    "FROM cte_rating_metrics\n",
    ")\n",
    "# now combine everything into one table\n",
    "SELECT\n",
    "    tf.star_rating,\n",
    "    tf.tf_rank AS term_ranking,\n",
    "    tf.term AS tf_term,\n",
    "    df.term AS df_term,\n",
    "    tfidf.term AS tfidf_term\n",
    "FROM cte_ranked AS tf\n",
    "INNER JOIN cte_ranked AS df\n",
    "    ON tf.star_rating = df.star_rating\n",
    "    AND tf.tf_rank = df.df_rank\n",
    "INNER JOIN cte_ranked AS tfidf\n",
    "    ON tf.star_rating = tfidf.star_rating\n",
    "    AND tf.tf_rank = tfidf.tfidf_rank\n",
    "ORDER BY 1,2;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed551807",
   "metadata": {},
   "source": [
    "### 2.10.1 Inspecting Outputs\n",
    "\n",
    "Now that this analysis is complete - let's see if our TF-IDF terms give us more insights around the 1 and 5 star ratings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM cali_classics_analysis_df\n",
    "WHERE star_rating IN (1, 5)\n",
    "AND term_ranking <= 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26192666",
   "metadata": {},
   "source": [
    "### 2.10.2 Critically Thinking About TF-IDF\n",
    "\n",
    "So in theory - although TF-IDF is great at highlighting distinctive or unique terms within a document relative to the overall collection of documents in a corpus - it's not always that simple!\n",
    "\n",
    "In our example - we can see that creating a sub-corpus of documents that are relevant to each of our tour products yields more insights out of our TD-IDF analysis. However - we can also see that the TF-IDF when we reduce the scope to only look at an individual product also yields quite similar results to the overall term-frequency metrics that we calculate.\n",
    "\n",
    "This is another timely reminder that we always need to be quite critical when analyzing our data and to always be open to experimenting with a variety of methods and approaches!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324baf1",
   "metadata": {},
   "source": [
    "## 2.11 Top Terms for 5 Star Reviews\n",
    "\n",
    "Let's now implement a final SQL script for this NLP text cleaning tutorial where we can perform the in-product TF-IDF analysis for our reviews to return top 10 terms for each product!\n",
    "\n",
    "We'll re-use much of our logic from previous steps - but this time we'll just remove our `WHERE` filter on the product and apply it instead on the `star_rating` field.\n",
    "\n",
    "Let's store our final output as `reviews_5_star_terms_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28300dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_5_star_terms_df <<\n",
    "WITH cte_terms AS (\n",
    "SELECT\n",
    "    products.product_name,\n",
    "    tokens.review_id,\n",
    "    # Use LAG window function to take combine 2 positional terms into a bi-gram\n",
    "    LAG(tokens.term) OVER (PARTITION BY tokens.review_id ORDER BY tokens.position) || ' ' || term AS term\n",
    "FROM reviews_tokenized_df AS tokens\n",
    "INNER JOIN reviews\n",
    "    ON tokens.review_id = reviews.review_id\n",
    "INNER JOIN products\n",
    "    ON reviews.product_id = products.product_id\n",
    "WHERE reviews.star_rating = 5\n",
    "),\n",
    "cte_tf AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "FROM cte_terms\n",
    "# Apply a WHERE filter to remove the first bi-gram which will be NULL\n",
    "WHERE term IS NOT NULL\n",
    "GROUP BY\n",
    "    product_name,\n",
    "    review_id,\n",
    "    term\n",
    "),\n",
    "cte_df AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "FROM cte_terms\n",
    "# Apply a WHERE filter to remove the first bi-gram which will be NULL\n",
    "WHERE term IS NOT NULL\n",
    "GROUP BY\n",
    "    product_name,\n",
    "    term\n",
    "),\n",
    "cte_doc_count AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    COUNT(DISTINCT review_id) AS document_count\n",
    "FROM cte_terms\n",
    "GROUP BY product_name\n",
    "),\n",
    "cte_vocab AS (\n",
    "SELECT DISTINCT\n",
    "    product_name,\n",
    "    term\n",
    "FROM cte_df\n",
    "),\n",
    "cte_combined AS (\n",
    "SELECT\n",
    "    tf.product_name,\n",
    "    tf.review_id,\n",
    "    vocab.term,\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    docs.document_count\n",
    "FROM cte_vocab AS vocab\n",
    "LEFT JOIN cte_tf AS tf\n",
    "    ON vocab.product_name = tf.product_name\n",
    "    AND vocab.term = tf.term\n",
    "LEFT JOIN cte_df AS df\n",
    "    ON vocab.product_name = df.product_name\n",
    "    AND vocab.term = df.term\n",
    "LEFT JOIN cte_doc_count AS docs\n",
    "    ON docs.product_name = tf.product_name\n",
    "),\n",
    "cte_nlp_metrics AS (\n",
    "SELECT\n",
    "    nlp.product_name,\n",
    "    nlp.review_id,\n",
    "    reviews.star_rating,\n",
    "    nlp.term,\n",
    "    nlp.term_frequency,\n",
    "    nlp.document_frequency,\n",
    "    nlp.term_frequency * LN(nlp.document_count / nlp.document_frequency) AS tf_idf\n",
    "FROM cte_combined AS nlp\n",
    "INNER JOIN reviews\n",
    "    ON nlp.review_id = reviews.review_id\n",
    "),\n",
    "cte_rating_metrics AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    star_rating,\n",
    "    term,\n",
    "    AVG(term_frequency) AS term_frequency,\n",
    "    AVG(document_frequency) AS document_frequency,\n",
    "    AVG(tf_idf) AS tf_idf\n",
    "FROM cte_nlp_metrics AS tfidf\n",
    "GROUP BY\n",
    "    product_name,\n",
    "    star_rating,\n",
    "    term\n",
    "),\n",
    "cte_ranked AS (\n",
    "SELECT\n",
    "    product_name,\n",
    "    star_rating,\n",
    "    term,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY term_frequency DESC) AS tf_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY document_frequency DESC) AS df_rank,\n",
    "    ROW_NUMBER() OVER (PARTITION BY product_name, star_rating ORDER BY tf_idf DESC) AS tfidf_rank\n",
    "FROM cte_rating_metrics\n",
    ")\n",
    "# now combine everything into one table\n",
    "SELECT\n",
    "    tf.product_name,\n",
    "    tf.star_rating,\n",
    "    tf.tf_rank AS term_ranking,\n",
    "    tf.term AS tf_term,\n",
    "    df.term AS df_term,\n",
    "    tfidf.term AS tfidf_term\n",
    "FROM cte_ranked AS tf\n",
    "INNER JOIN cte_ranked AS df\n",
    "    ON tf.product_name = df.product_name\n",
    "    AND tf.star_rating = df.star_rating\n",
    "    AND tf.tf_rank = df.df_rank\n",
    "INNER JOIN cte_ranked AS tfidf\n",
    "    ON tf.product_name = tfidf.product_name\n",
    "    AND tf.star_rating = tfidf.star_rating\n",
    "    AND tf.tf_rank = tfidf.tfidf_rank\n",
    "ORDER BY 1,2,3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Pandas option to help us show all rows from our output\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%sql SELECT * FROM reviews_5_star_terms_df WHERE term_ranking <= 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Pandas option to only show top 10 rows\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc3bf9",
   "metadata": {},
   "source": [
    "# 3. Implement A/B Framework\n",
    "\n",
    "The final part of our NLP challenge is to design a measurement framework to quantify the uplift of an AI experiment.\n",
    "\n",
    "Although we won't be able to implement the advanced NLP components ourselves using SQL - we will definitely be able to analyze the sales uplift by investigating our `visits`, `sales` and `features` tables in our SQL database.\n",
    "\n",
    "In our Explore California business example - I've generated some simulated AI experiment results for the year 2026.\n",
    "\n",
    "In the first 3 months of the calendar year - 50% of the website visitors are exposed to an AI powered \"NLP search\" tool.\n",
    "\n",
    "We will be using this data to compare our sales performance for this 3 month period compared to a few different baselines.\n",
    "\n",
    "Let's again revisit our ERD to make sure we can visualize how we will join our tables together to come up with a technical solution.\n",
    "\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e92d8",
   "metadata": {},
   "source": [
    "## 3.1 Inspect Raw Data\n",
    "\n",
    "We can begin by taking a look at the `sales`, `visits` and `features` tables - these will be key to our analysis!\n",
    "\n",
    "We can also link up our sales with each relevant product to identify the price in $USD using the `product_id` - we'll keep this up our sleeve for later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM sales LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00b39f",
   "metadata": {},
   "source": [
    "We can see that the `visit_id` can be used to link each sales transaction to specific website visit - let's take a look at what we have in the visits table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM visits LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aca04a",
   "metadata": {},
   "source": [
    "And finally - we've got a `features` table which identifies the `visit_id` values where an AI powered feature was shown.\n",
    "\n",
    "For our first NLP search feature - we can apply a filter on this table for \"Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84265eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM features\n",
    "WHERE feature = 'Search'\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19201f3",
   "metadata": {},
   "source": [
    "## 3.3 Experimental Analysis\n",
    "\n",
    "Let's have a go at combining all of these tables to generate a single table where we can apply all of our analysis.\n",
    "\n",
    "The required columns that we'll need for this table are below:\n",
    "\n",
    "* visit_timestamp\n",
    "* visit_id\n",
    "* user_id\n",
    "* feature_flag (if it exists)\n",
    "* sale_flag (if it exists)\n",
    "* sale_amount (use the `products` table to find the USD price)\n",
    "\n",
    "Let's also filter this table to only include the first 3 months of 2026 - this is when our theoretical AI experiment is running.\n",
    "\n",
    "We will store out outputs as `experiment_analysis_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql experiment_analysis_df <<\n",
    "SELECT\n",
    "    visits.visit_timestamp,\n",
    "    visits.visit_id,\n",
    "    visits.user_id,\n",
    "    CASE WHEN features.feature IS NOT NULL THEN 1 ELSE 0 END AS feature_flag,\n",
    "    CASE WHEN sales.sale_id IS NOT NULL THEN 1 ELSE 0 END AS sale_flag,\n",
    "    COALESCE(products.price_usd, 0) AS sale_amount\n",
    "FROM visits\n",
    "LEFT JOIN features\n",
    "    ON visits.visit_id = features.visit_id\n",
    "LEFT JOIN sales\n",
    "    ON visits.visit_id = sales.visit_id\n",
    "LEFT JOIN products\n",
    "    ON sales.product_id = products.product_id\n",
    "WHERE visits.visit_timestamp BETWEEN DATE '2026-01-01' AND DATE '2026-03-31';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5344e",
   "metadata": {},
   "source": [
    "## 3.4 Answering Business Questions\n",
    "\n",
    "Let's use `experiment_analysis_df` to answer a few relevant questions at a macro level before we zoom into the experiment analysis.\n",
    "\n",
    "1. How many sales are there per month and what is the monthly total sale amount?\n",
    "2. What is the total number of visits per month?\n",
    "3. What percentage of visits lead to a sale?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e6470",
   "metadata": {},
   "source": [
    "### 3.4.1 Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "# How many sales are there per month and what is the monthly total sale amount?\n",
    "SELECT\n",
    "    DATE_TRUNC('MON', visit_timestamp) AS sales_month,\n",
    "    SUM(sale_flag) AS sales_count,\n",
    "    SUM(sale_amount) AS sales_amount\n",
    "FROM experiment_analysis_df\n",
    "WHERE sale_flag = 1\n",
    "GROUP BY 1\n",
    "ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde163f5",
   "metadata": {},
   "source": [
    "### 3.4.2 Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc03034",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "# 2. What is the total number of visits per month?\n",
    "SELECT\n",
    "    DATE_TRUNC('MON', visit_timestamp) AS sales_month,\n",
    "    COUNT(DISTINCT visit_id) AS visit_count\n",
    "FROM experiment_analysis_df\n",
    "GROUP BY 1\n",
    "ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559f617",
   "metadata": {},
   "source": [
    "### 3.4.3 Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "# What percentage of visits lead to a sale?\n",
    "SELECT\n",
    "    DATE_TRUNC('MON', visit_timestamp) AS sales_month,\n",
    "    COUNT(DISTINCT visit_id) AS visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS sales_count,\n",
    "    sales_count / visit_count AS conversion_rate\n",
    "FROM experiment_analysis_df\n",
    "GROUP BY 1\n",
    "ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3a9f4",
   "metadata": {},
   "source": [
    "## 3.5 Experiment Questions\n",
    "\n",
    "Now let's add back in the extra slice of the `feature_flag` to analyze our sales and conversion performance in a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    DATE_TRUNC('MON', visit_timestamp) AS sales_month,\n",
    "    feature_flag,\n",
    "    COUNT(DISTINCT visit_id) AS visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS sales_count,\n",
    "    SUM(sale_amount) AS sales_amount,\n",
    "    sales_count / visit_count AS conversion_rate\n",
    "FROM experiment_analysis_df\n",
    "GROUP BY 1,2\n",
    "ORDER BY 1,2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e2e21",
   "metadata": {},
   "source": [
    "## 3.6 Quantifying Uplift\n",
    "\n",
    "Here we can see there is some slight uplift for the visits where the `feature_flag` is present. Let's quantify the exact aggregated uplift for the entire experiment period.\n",
    "\n",
    "There are many many ways to do this using SQL - but let's keep this simple and split up our analysis into 2 CTEs and combine them together to calculate the uplift metrics.\n",
    "\n",
    "We generally will refer to the existing experience or the records where `feature_flag = 0` as the \"control\" and the group which were exposed to the feature would be considered as the \"target\" group.\n",
    "\n",
    "Because we can see that traffic is roughly split to 50/50 for this experiment - we can calculate incremental values by simply finding the difference between the target and control sale counts and amounts values.\n",
    "\n",
    "We'll store our output as `experiment_results_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql experiment_results_df <<\n",
    "WITH cte_control AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS control_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS control_sales_count,\n",
    "    SUM(sale_amount) AS control_sales_amount,\n",
    "    control_sales_count / control_visit_count AS control_conversion_rate\n",
    "FROM experiment_analysis_df\n",
    "WHERE feature_flag = 0\n",
    "),\n",
    "cte_target AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS target_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS target_sales_count,\n",
    "    SUM(sale_amount) AS target_sales_amount,\n",
    "    target_sales_count / target_visit_count AS target_conversion_rate\n",
    "FROM experiment_analysis_df\n",
    "WHERE feature_flag = 1\n",
    ")\n",
    "SELECT\n",
    "    # uplift metrics\n",
    "    target_sales_count - control_sales_count AS incremental_sales_count,\n",
    "    target_sales_amount - control_sales_amount AS incremental_sales_amount,\n",
    "    100 * ( target_sales_count / control_sales_count - 1 ) AS sales_count_uplift,\n",
    "    100 * ( target_sales_amount / control_sales_amount - 1 ) AS sales_amount_uplift,\n",
    "    100 * ( target_conversion_rate / control_conversion_rate - 1 ) AS conversion_uplift,\n",
    "    control.*,\n",
    "    target.*\n",
    "FROM cte_target AS target\n",
    "CROSS JOIN cte_control AS control;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad002253",
   "metadata": {},
   "source": [
    "## 3.7 Z-Test for Two Proportions\n",
    "\n",
    "We can take this one step further and calculate the statistical validity of our experiment using what's known as an A/B test.\n",
    "\n",
    "We'll use SQL to implement what is known as a \"test of two proportions\" where we will calculate a z-score using some inputs from our experiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225b525",
   "metadata": {},
   "source": [
    "### 3.7.1 One-Tail vs Two-Tailed Tests\n",
    "\n",
    "For our experiment - since we have an uplift in the conversion rate - we want to perform a one-tailed test of two proportions test as we are only interested in testing if this positive increase is in fact significant or not.\n",
    "\n",
    "Generally these tests are performed at an alpha level = 0.05 allowing for a 5% error or false-positive rate from our given experiment results.\n",
    "\n",
    "A one-tailed test is comparing one group to another when trying to confirm a hypothesis that our \"target\" group is performing better than our \"control\" group. A two-tailed test is just trying to confirm a different hypothesis - that our target group is different to our control where the directionality of the test is not considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd5b78",
   "metadata": {},
   "source": [
    "### 3.7.2 Calculating the Z-Score\n",
    "\n",
    "For our tests - we will want to set the z-score critical value threshold at 1.645 for a 5% false positive rate for our one-tailed test. The z-score a statistical measure that shows how unusual or typical a result is when compared to the null-hypothesis.\n",
    "\n",
    "In our case - we want a higher z-score to disprove our null hypothesis that the target group does not perform better than the control group. A score near 0 means that the results from the experiment are likely to follow the null hypothesis - while a higher value provides us more information to decide whether the experiment results are statistically significant.\n",
    "\n",
    "The z-score is calculated as below:\n",
    "\n",
    "$z = \\frac{p_1 - p_2}{\\sqrt{p(1 - p) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $p_1 = \\dfrac{x_1}{n_1}$ ‚Äî Target group conversion rate  \n",
    "- $p_2 = \\dfrac{x_2}{n_2}$ ‚Äî Control group conversion rate\n",
    "- $p = \\dfrac{x_1 + x_2}{n_1 + n_2}$ ‚Äî Overall conversion rate\n",
    "- $x_1$, $x_2$ ‚Äî number of sales in each target and control group  \n",
    "- $n_1$, $n_2$ ‚Äî number of visits/observations in each target and control group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b6c6f",
   "metadata": {},
   "source": [
    "### 3.7.3 Z-Score Implementation in SQL\n",
    "\n",
    "We can implement this directly in SQL as we already have most of these values ready to go - the only thing we'll need to add in is the overall conversion rate by adding up our visits and sales for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919280ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  (target_sales_count + control_sales_count) /\n",
    "    (target_visit_count + control_visit_count) AS overall_conversion_rate,\n",
    "  # numerator\n",
    "  (target_conversion_rate - control_conversion_rate) /\n",
    "  # denominator\n",
    "  SQRT(\n",
    "    overall_conversion_rate * (1 - overall_conversion_rate) *\n",
    "    (1 / target_visit_count + 1 / control_visit_count)\n",
    "  ) AS z_score,\n",
    "  CASE WHEN z_score >= 1.645 THEN 'Significant' ELSE 'Not Significant' END AS test_result\n",
    "FROM experiment_results_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958550",
   "metadata": {},
   "source": [
    "## 3.8 Sequential Comparison\n",
    "\n",
    "Although the best practice is to compare sales and conversion for the exact same analysis period using some sort of split-test or A/B test. We should also explore a few other methods of measuring impact to illustrate the key differences and potential limitations of other baselines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233efad9",
   "metadata": {},
   "source": [
    "### 3.8.1 Comparing 3 Months Before\n",
    "\n",
    "Let's say we want to compare just a simple 3 months before and 3 months during the experiment - let's just assume that we haven't split the traffic at all or we didn't capture the individual `feature` value for each visit but we just blindly ran a campaign.\n",
    "\n",
    "Let's compare the 3 months from Jan to March 2026 with October to Dec 2025 - and we'll see that there is still an uplift!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH cte_base AS (\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN visits.visit_timestamp BETWEEN DATE '2025-10-01' AND DATE '2025-12-31' THEN 'before'\n",
    "        ELSE 'after'\n",
    "    END AS experiment_group,\n",
    "    visits.visit_id,\n",
    "    visits.user_id,\n",
    "    CASE WHEN sales.sale_id IS NOT NULL THEN 1 ELSE 0 END AS sale_flag,\n",
    "    COALESCE(products.price_usd, 0) AS sale_amount\n",
    "FROM visits\n",
    "LEFT JOIN sales\n",
    "    ON visits.visit_id = sales.visit_id\n",
    "LEFT JOIN products\n",
    "    ON sales.product_id = products.product_id\n",
    "WHERE visits.visit_timestamp BETWEEN DATE '2025-10-01' AND DATE '2026-03-31'\n",
    "),\n",
    "cte_before AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS before_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS before_sales_count,\n",
    "    SUM(sale_amount) AS before_sales_amount,\n",
    "    before_sales_count / before_visit_count AS before_conversion_rate\n",
    "FROM cte_base\n",
    "WHERE experiment_group = 'before'\n",
    "),\n",
    "cte_after AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS after_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS after_sales_count,\n",
    "    SUM(sale_amount) AS after_sales_amount,\n",
    "    after_sales_count / after_visit_count AS after_conversion_rate\n",
    "FROM cte_base\n",
    "WHERE experiment_group = 'after'\n",
    "),\n",
    "cte_metrics AS (\n",
    "SELECT\n",
    "    # uplift metrics\n",
    "    after_sales_count - before_sales_count AS incremental_sales_count,\n",
    "    after_sales_amount - before_sales_amount AS incremental_sales_amount,\n",
    "    100 * ( after_sales_count / before_sales_count - 1 ) AS sales_count_uplift,\n",
    "    100 * ( after_sales_amount / before_sales_amount - 1 ) AS sales_amount_uplift,\n",
    "    100 * ( after_conversion_rate / before_conversion_rate - 1 ) AS conversion_uplift,\n",
    "    before.*,\n",
    "    after.*\n",
    "FROM cte_after AS after\n",
    "CROSS JOIN cte_before AS before\n",
    ")\n",
    "SELECT\n",
    "  (after_sales_count + before_sales_count) /\n",
    "    (after_visit_count + before_visit_count) AS overall_conversion_rate,\n",
    "  # numerator\n",
    "  (after_conversion_rate - before_conversion_rate) /\n",
    "  # denominator\n",
    "  SQRT(\n",
    "    overall_conversion_rate * (1 - overall_conversion_rate) *\n",
    "    (1 / after_visit_count + 1 / before_visit_count)\n",
    "  ) AS z_score,\n",
    "  CASE WHEN z_score >= 1.96 THEN 'Significant' ELSE 'Not Significant' END AS test_result,\n",
    "  *\n",
    "FROM cte_metrics;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b965c",
   "metadata": {},
   "source": [
    "### 3.8.2 Critical Analysis\n",
    "\n",
    "We can see that we still return a significant result even though we already know that there is no other intervention applied or experiment that is running!\n",
    "\n",
    "This is due to none other than **seasonality** - a very common enemy when it comes to comparing experiment results sequentially. This is exactly one of the reasons why we like to run experiments in the same time frame with split tests.\n",
    "\n",
    "The seasonality is effectively removed when you compare like-for-like periods as we showed in our A/B test and we can rely on these results much more than just looking at a simple before and after analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33853ec6",
   "metadata": {},
   "source": [
    "## 3.9 Year-on-Year Comparison\n",
    "\n",
    "Another method to account for seasonality is to compare results for the same period - but for 1 year earlier.\n",
    "\n",
    "Here lies another danger for experimentation testing - especially in the world of AI and just in general for all technology!\n",
    "\n",
    "A lot can happen in 1 year - however we also need to confirm to ourselves that there is no seasonality involved when running our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffdeba",
   "metadata": {},
   "source": [
    "### 3.9.1 SQL Implementation\n",
    "\n",
    "Let's illustrate this example by comparing the 3 months where we were running our experiment with the same 3 months of data from 2025 one year earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH cte_base AS (\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN visits.visit_timestamp BETWEEN DATE '2025-01-01' AND DATE '2025-03-31' THEN 'before'\n",
    "        ELSE 'after'\n",
    "    END AS experiment_group,\n",
    "    visits.visit_id,\n",
    "    visits.user_id,\n",
    "    CASE WHEN sales.sale_id IS NOT NULL THEN 1 ELSE 0 END AS sale_flag,\n",
    "    COALESCE(products.price_usd, 0) AS sale_amount\n",
    "FROM visits\n",
    "LEFT JOIN sales\n",
    "    ON visits.visit_id = sales.visit_id\n",
    "LEFT JOIN products\n",
    "    ON sales.product_id = products.product_id\n",
    "WHERE visits.visit_timestamp BETWEEN DATE '2025-01-01' AND DATE '2025-03-31'\n",
    "OR visits.visit_timestamp BETWEEN DATE '2026-01-01' AND DATE '2026-03-31'\n",
    "),\n",
    "cte_before AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS before_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS before_sales_count,\n",
    "    SUM(sale_amount) AS before_sales_amount,\n",
    "    before_sales_count / before_visit_count AS before_conversion_rate\n",
    "FROM cte_base\n",
    "WHERE experiment_group = 'before'\n",
    "),\n",
    "cte_after AS (\n",
    "SELECT\n",
    "    COUNT(DISTINCT visit_id) AS after_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS after_sales_count,\n",
    "    SUM(sale_amount) AS after_sales_amount,\n",
    "    after_sales_count / after_visit_count AS after_conversion_rate\n",
    "FROM cte_base\n",
    "WHERE experiment_group = 'after'\n",
    "),\n",
    "cte_metrics AS (\n",
    "SELECT\n",
    "    # uplift metrics\n",
    "    after_sales_count - before_sales_count AS incremental_sales_count,\n",
    "    after_sales_amount - before_sales_amount AS incremental_sales_amount,\n",
    "    100 * ( after_sales_count / before_sales_count - 1 ) AS sales_count_uplift,\n",
    "    100 * ( after_sales_amount / before_sales_amount - 1 ) AS sales_amount_uplift,\n",
    "    100 * ( after_conversion_rate / before_conversion_rate - 1 ) AS conversion_uplift,\n",
    "    before.*,\n",
    "    after.*\n",
    "FROM cte_after AS after\n",
    "CROSS JOIN cte_before AS before\n",
    ")\n",
    "SELECT\n",
    "  (after_sales_count + before_sales_count) /\n",
    "    (after_visit_count + before_visit_count) AS overall_conversion_rate,\n",
    "  # numerator\n",
    "  (after_conversion_rate - before_conversion_rate) /\n",
    "  # denominator\n",
    "  SQRT(\n",
    "    overall_conversion_rate * (1 - overall_conversion_rate) *\n",
    "    (1 / after_visit_count + 1 / before_visit_count)\n",
    "  ) AS z_score,\n",
    "  CASE WHEN z_score >= 1.96 THEN 'Significant' ELSE 'Not Significant' END AS test_result,\n",
    "  *\n",
    "FROM cte_metrics;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168101b5",
   "metadata": {},
   "source": [
    "### 3.9.2 Critical Analysis\n",
    "\n",
    "This demonstrates how we can compare our analysis periods to account for seasonality and also to perform split testing to analyse uplift directly in the same period for best practice.\n",
    "\n",
    "Although this isn't as good as running an A/B split test - sometimes using a year-on-year analysis helps us isolate our uplift effects while taking seasonality out of the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db66b8",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations!!!\n",
    "\n",
    "You made it to the end of this tutorial - we covered a lot of content so hopefully this Python/SQL notebook has been very useful and shows you a few ways which we can use SQL to prepare our NLP text data and measure the effectiveness of A/B test experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
