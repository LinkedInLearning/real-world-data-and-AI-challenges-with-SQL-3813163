{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1503fe30",
   "metadata": {},
   "source": [
    "# SQL for AI Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11905e5c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Natural Language Processing Challenge**\n",
    "\n",
    "In this Jupyter notebook - we'll quickly setup the DuckDB database, get you familiar with this Google Colab setup and then we'll dive into the NLP challenge exercises for the SQL for AI Projects course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdec9c4",
   "metadata": {},
   "source": [
    "### Challenge Exercises\n",
    "\n",
    "1. Clean webpage text data\n",
    "2. Investigate customer review text\n",
    "3. Implement A/B test framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1772483",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "\n",
    "First things first, let's load up our Python libraries and setup access to our database.\n",
    "\n",
    "Don't worry if you're not familiar with Python - we'll just need to run the very first cell to initialize our SQL instance and there will be clear instructions whenever there is some non-SQL components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cef12",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "To execute each cell in this notebook - you can click on the play button on the left of each cell or you could simply hit the `Run all` button on the top of the notebook just below the menu toolbar.\n",
    "\n",
    "This cell below will help us download and connect to a DuckDB database object within this notebook's temporary environment.\n",
    "\n",
    "There will also be a few outputs in the same cell including the following:\n",
    "\n",
    "* An interactive entity relationship diagram for our database is also as an output from the following cell. This will help us visualize all of the database tables and their relevant primary and foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup steps\n",
    "# ====================\n",
    "\n",
    "# These pip install commands are required for Google Colab notebook environment\n",
    "!pip install --upgrade --quiet duckdb==1.3.1\n",
    "!pip install --quiet duckdb-engine==0.17.0\n",
    "!pip install --quiet jupysql==0.11.1\n",
    "\n",
    "# Also need to setup Git LFS for large file dowloads\n",
    "# This helps us to download large files stored on GitHub\n",
    "!apt-get install git-lfs -y\n",
    "!git lfs install\n",
    "\n",
    "# Clone GitHub repo into a \"data\" folder\n",
    "!git clone https://github.com/LinkedInLearning/real-world-data-and-AI-challenges-with-SQL-3813163.git data\n",
    "\n",
    "# Need to change directory into \"data\" to run download database object\n",
    "%cd data\n",
    "!git lfs pull\n",
    "\n",
    "# Then we need to change directory back up so all our paths are correct!\n",
    "%cd ..\n",
    "\n",
    "# Time to import all our Python packages\n",
    "import duckdb\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Load the jupysql extension to enable us to run SQL code in code cells\n",
    "%load_ext sql\n",
    "\n",
    "# We can now set some basic Pandas settings for rendering SQL outputs\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "# This is a convenience function to print long strings into multiple lines\n",
    "# You'll see this in action later on in our tutorial!\n",
    "def wrap_print(text):\n",
    "    print(textwrap.fill(text, width=80))\n",
    "\n",
    "# This is some boilerplate code to help us format printed output with wrapping\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output pre {\n",
    "    white-space: pre-wrap;\n",
    "    word-break: break-word;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# Connecting to DuckDB\n",
    "# ====================\n",
    "\n",
    "# Setup the SQL connection\n",
    "connection = duckdb.connect(\"data/data.db\")\n",
    "%sql connection\n",
    "\n",
    "# Run a few test queries using both connections\n",
    "tables = connection.execute(\"SHOW TABLES\").fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "\n",
    "preview_counts_list = []\n",
    "for table_name in table_names:\n",
    "    try:\n",
    "        preview_counts_list.append(\n",
    "            connection.execute(f\"\"\"\n",
    "                SELECT '{table_name}' AS table_name,\n",
    "                    COUNT(*) AS record_count\n",
    "                FROM {table_name}\"\"\").fetchdf()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not preview table {table_name}: {e}\")\n",
    "        \n",
    "\n",
    "print(\"‚úÖ Database is now ready!\")\n",
    "\n",
    "print(\"\\nüìã Show count of rows from each table in the database:\")\n",
    "\n",
    "# Combine all dataframes in preview_df_list\n",
    "preview_counts_df = pd.concat(preview_counts_list, ignore_index=True)\n",
    "\n",
    "display(preview_counts_df)\n",
    "\n",
    "display(HTML('''\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>\n",
    "'''\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d40c1",
   "metadata": {},
   "source": [
    "# How to Run SQL Queries\n",
    "\n",
    "Let's quickly see how we can run SQL code in our Jupyter notebook.\n",
    "\n",
    "In our Colab environment we can run single or multi-line queries. We can also easily save the output of SQL queries as a local Pandas DataFrame object and even run subsequent SQL queries which can interact with these same DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d5990",
   "metadata": {},
   "source": [
    "## Single Line SQL Query\n",
    "\n",
    "We can use our notebook magic `%sql` at the start of a notebook cell to run a single line of SQL to query our database.\n",
    "\n",
    "Let's take a look at the first 5 rows from the `locations` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25719458",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28416b",
   "metadata": {},
   "source": [
    "## Multi-Line SQL Query\n",
    "\n",
    "We can also run multi-line SQL queries by using a different notebook magic `%%sql` where we now have 2 percentage signs.\n",
    "\n",
    "We'll apply a filter on our `location` dataset and return 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cf549",
   "metadata": {},
   "source": [
    "## Saving SQL Outputs\n",
    "\n",
    "By using the `<<` operator, we can assign the result of a SQL query (returned as a Pandas DataFrame) to a named Python variable in the notebook‚Äôs scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1c3df",
   "metadata": {},
   "source": [
    "### Single Line Assignment\n",
    "\n",
    "We can specify the name of the output variable directly after the `%sql` or `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36119368",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql single_magic_df << SELECT * FROM locations LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91656938",
   "metadata": {},
   "source": [
    "We can now reference the Python variable directly as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python notebook scope\n",
    "single_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc8169",
   "metadata": {},
   "source": [
    "We can also use this same variable as a table reference within a DuckDB `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM single_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fc9bb",
   "metadata": {},
   "source": [
    "### Multi-line Assignment\n",
    "\n",
    "This assignment using `<<` also works with the `%%sql` (multi-line) magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ba366",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql multi_magic_df <<\n",
    "SELECT\n",
    "  location_name,\n",
    "  description\n",
    "FROM locations\n",
    "WHERE location_id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad734fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataframe\n",
    "multi_magic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f452d",
   "metadata": {},
   "source": [
    "When referencing the Python variable within DuckDB, we can also use it inside a multi-line SQL query using the `%%sql` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05992467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM multi_magic_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebe3cc",
   "metadata": {},
   "source": [
    "# 1. Clean Text Data\n",
    "\n",
    "In this first exercise - we‚Äôll clean and prepare the `html_data` column from the locations table so it‚Äôs ready for NLP.\n",
    "\n",
    "Here is an overview of what we will cover!\n",
    "\n",
    "* Deep dive into using `REGEXP_REPLACE`\n",
    "* Remove HTML tags\n",
    "* Clean up newline, whitespace and `&` characters\n",
    "* Apply advanced find-and-replace using `REGEXP_REPLACE`\n",
    "* Maintain original document structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80ab2e",
   "metadata": {},
   "source": [
    "## 1.1 Inspect Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be20d2",
   "metadata": {},
   "source": [
    "### 1.1.1 Viewing Raw HTML Data\n",
    "\n",
    "We'll apply a filter on our locations table to view `location_id = 46` which contains the LACMA Los Angeles County Museum of Art location details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql museum_html_example_df << SELECT html_data FROM locations WHERE location_id = 46;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1277475",
   "metadata": {},
   "source": [
    "We‚Äôll need to use the `.loc` method in Pandas to inspect the raw HTML. In this case, our expression below is how we would implement - ‚ÄúGet the value from the first row of the DataFrame, specifically from the html_data column.‚Äù\n",
    "\n",
    "```python\n",
    "museum_html_example_df.loc[0, \"html_data\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also save this variable for use in a later cell\n",
    "museum_raw_html_string = museum_html_example_df.loc[0, \"html_data\"]\n",
    "\n",
    "print(museum_raw_html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc499313",
   "metadata": {},
   "source": [
    "### 1.1.2 Inspect Rendered Data\n",
    "\n",
    "As we can see - there is a lot of cleaning that needs to be done with this!\n",
    "\n",
    "Let's take a look at how we can print out our HTML and see how it would render on an actual webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dcf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(museum_raw_html_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cbb776",
   "metadata": {},
   "source": [
    "## 1.2 Data Transformations\n",
    "\n",
    "After inspecting our example HTML code and our rendered data above - we can come up with a list of requirements for our data transformations.\n",
    "\n",
    "The order of these transformations is important as we won't be able to apply find-and-replace on our HTML tags if we were to remove the first!\n",
    "\n",
    "1. Remove duplicated title data\n",
    "2. Apply transformations to maintain document structure\n",
    "3. Remove HTML tags\n",
    "4. Clean up whitespace and newline characters\n",
    "5. Fix up web ampersand `&` issues\n",
    "6. Remove redundant information at the end of text\n",
    "\n",
    "We'll get very familiar with the `REGEXP_REPLACE` function as we'll be using it throughout this tutorial to accomplish these text data transformations.\n",
    "\n",
    "You can think of it as a flexible find-and-replace tool that we can use in SQL to identify key patterns in our text data which we want to remove or replace with a certain set of characters.\n",
    "\n",
    "The `REGEXP_REPLACE` function in DuckDB has 4 positional parameters:\n",
    "\n",
    "1. **source_string** ‚Äì The text input that we want to search through  \n",
    "2. **pattern** ‚Äì The regular expression pattern used to find matches  \n",
    "3. **replacement** ‚Äì The string that will replace any text matching the pattern  \n",
    "4. **occurrence (optional)** ‚Äì Which match to replace (by default, it replaces **all** matches)\n",
    "\n",
    "Note for our SQL implementation we use `'g'` for the occurrence parameter to explicitly ask our SQL engine to replace all occurrences as it's not always common knowledge the \"all\" matches are replaced as default or the behaviour might differ from one SQL dialect to another!\n",
    "\n",
    "Let's first focus on the regular expression patterns we will use for our data transformation steps.\n",
    "\n",
    "We will be using 6 regular expressions for each step in our text data transformations.\n",
    "\n",
    "Let's step through these one at a time before implementing the complete SQL query.\n",
    "\n",
    "With the exception of step 2 and 5 - all of our matches will be replaced with either a blank character to remove the match or a single whitespace.\n",
    "\n",
    "| Step | Regex Pattern                 | Purpose                                           |\n",
    "|------|-------------------------------|---------------------------------------------------|\n",
    "| 1    | `(?si)<title>.*?</title>`     | Remove `<title>` contents                         |\n",
    "| 2    | `(?si)<h2>(.*?)</h2>`         | Wrap `<h2>` contents with `|`                     |\n",
    "| 3    | `<[^>]+>`                     | Remove all remaining HTML tags                    |\n",
    "| 4    | `[\\n\\r\\t\\(\\) ]+`              | Normalize whitespace and remove `()`, tabs, etc.  |\n",
    "| 5    | `&amp;`                       | Replace HTML-encoded `&`                          |\n",
    "| 6    | `\\| Useful Links.*$`          | Remove footer-like links from the end             |\n",
    "\n",
    "Let's breakdown each Regex Pattern with a detailed summary below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640e182",
   "metadata": {},
   "source": [
    "### 1.2.1 Remove \\<title\\> Tags\n",
    "\n",
    "We have the following regex for this step: `(?si)<title>.*?</title>`\n",
    "\n",
    "Once we match these rules - we will replace the match with an empty string for removal.\n",
    "\n",
    "| Component             | Description                                               |\n",
    "|-----------------------|-----------------------------------------------------------|\n",
    "| `(?si)`               | Enables case-insensitive (`i`) and dot-all (`s`) modes    |\n",
    "| `<title>`             | Matches the literal opening `<title>` tag                 |\n",
    "| `.*?`                 | Lazily matches any characters (including newlines)        |\n",
    "| `</title>`            | Matches the closing `</title>` tag                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fbd70",
   "metadata": {},
   "source": [
    "### 1.2.2 Wrap `<h2>` contents with `|`\n",
    "\n",
    "We have the following regex for this step: `(?si)<h2>(.*?)</h2>`\n",
    "\n",
    "The difference with this transformation step is that we have a \"capture group\" in brackets that we re-use as `\\1` in our second positional parameter for the `REGEXP_REPLACE` function.\n",
    "\n",
    "This allows us to retain the structure of our original HTML document by surrounding the h2 heading tags with pipe characters so our downstream NLP algorithms can capture this context as it parses our text inputs.\n",
    "\n",
    "| Component             | Description                                               |\n",
    "|-----------------------|-----------------------------------------------------------|\n",
    "| `(?si)`               | Case-insensitive, dot-all mode                            |\n",
    "| `<h2>`                | Matches the opening `<h2>` tag                            |\n",
    "| `(.*?)`               | Lazily captures content inside the tag                    |\n",
    "| `</h2>`               | Matches the closing `</h2>` tag                           |\n",
    "| Replacement: `\\| \\1 \\|` | Replaces match with pipe-wrapped captured content         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769e000",
   "metadata": {},
   "source": [
    "### 1.2.3 Remove Remaining HTML Tags\n",
    "\n",
    "After we've transformed our title and h2 HTML tags - we can then remove the rest of them from our text inputs using the regex `<[^>]+>` and replacing this with an empty string `''`\n",
    "\n",
    "Note that the square brackets `[ ... ]` denotes a \"character class\" where the hat `^>` inside the square brackets mean \"any character except >\" and the following `+` means one or more occurences of this character class. \n",
    "\n",
    "| Component     | Description                                                      |\n",
    "|----------------|-----------------------------------------------------------------|\n",
    "| `<`           | Matches the opening angle bracket of a tag                       |\n",
    "| `[^>]+`       | Matches one or more characters that are not `>`                  |\n",
    "| `>`           | Matches the closing angle bracket of a tag                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4ee30",
   "metadata": {},
   "source": [
    "### 1.2.4 Normalize Whitespace and Extra Characters\n",
    "\n",
    "Usually after removing the HTML tags might lead to excessive amounts of newlines or other unwanted characters in a text string. We will replace these occurences with a single whitespace to normalize our text outputs.\n",
    "\n",
    "Here we use the same character class `[ ... ]` but this time we have a range of other characters. Note that the open and close brackets need to be escaped with a backslash character so the Regex engine doesn't get confused with the \"capture class\" that we've used previously!\n",
    "\n",
    "| Component      | Description                                                       |\n",
    "|----------------|-------------------------------------------------------------------|\n",
    "| `[\\n\\r\\t\\(\\) ]`| Character class: matches newlines, carriage returns, tabs, `()`, and spaces |\n",
    "| `+`            | Matches one or more of the above characters                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338575ea",
   "metadata": {},
   "source": [
    "### 1.2.5 Replace HTML-Encoded Ampersands\n",
    "\n",
    "This is a straightforward find-and-replace with the HTML encoded ampersand `&amp;` with a simple `&` character.\n",
    "\n",
    "| Component | Description                       |\n",
    "|-----------|-----------------------------------|\n",
    "| `&amp;`   | Matches the literal string `&amp;` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07397f",
   "metadata": {},
   "source": [
    "### 1.2.6 Remove Trailing Sections\n",
    "\n",
    "Finally - we can remove the redundant `Useful Links` section that has the hyperlink information removed by our HTML tag step. The `.*` usage is quite common so you will likely see it in other SQL code where `REGEXP_REPLACE` transformations occur!\n",
    "\n",
    "| Component          | Description                                                 |\n",
    "|--------------------|-------------------------------------------------------------|\n",
    "| `\\|`               | Escaped pipe character (`|`), matched literally             |\n",
    "| ` Useful Links`    | Fixed string match                                          |\n",
    "| `.*`               | Matches any characters after ‚ÄúUseful Links‚Äù                 |\n",
    "| `$`                | Anchors match to the **end of the line**                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ad93d",
   "metadata": {},
   "source": [
    "## 1.2.7 SQL Implementation\n",
    "\n",
    "Now let's perform all of these transformations using a series of \"nested\" `REGEXP_REPLACE` functions - and we'll add one more `TRIM` call at the beginning of the nested stack of functions to remove any leading or trailing whitespace characters.\n",
    "\n",
    "At first - this query will look quite long and complex - but it's easy to understand if we were to read the transformation logic from \"inside-out\" where we begin with the inner-most nested `REGEXP_REPLACE` function call and work sequentially outwards.\n",
    "\n",
    "Also note how each part of the query is indented one level with each function call - this helps us read the code a little bit easier and I've found that it helps me debug any issues as I develop the code from scratch this way!\n",
    "\n",
    "We can store our outputs as `locations_transformed_df` and we can quickly check that our transformations look alright for the previous records we were checking `location_id = 46` for our Museum example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093404ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql locations_transformed_df <<\n",
    "# ------------------------------------------------------\n",
    "# 1. Extract and clean text from raw HTML in locations\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "  # Retain all original metadata columns from the locations table\n",
    "  locations.*,\n",
    "\n",
    "  # Apply layered text cleaning using nested REGEXP_REPLACE\n",
    "  TRIM(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              # Step 1: Remove <title> tags and their content\n",
    "              REGEXP_REPLACE(html_data, '(?si)<title>.*?</title>', '', 'g'),\n",
    "\n",
    "              # Step 2: Preserve <h2> tag content and wrap with pipes\n",
    "              '(?si)<h2>(.*?)</h2>', '| \\1 |', 'g'\n",
    "            ),\n",
    "\n",
    "            # Step 3: Strip out all remaining HTML tags\n",
    "            '<[^>]+>', '', 'g'\n",
    "          ),\n",
    "\n",
    "          # Step 4: Normalize whitespace and remove special characters\n",
    "          '[\\n\\r\\t\\(\\) ]+', ' ', 'g'\n",
    "        ),\n",
    "\n",
    "        # Step 5: Replace HTML entities (e.g., &amp;) with literal symbols\n",
    "        '&amp;', '&', 'g'\n",
    "      ),\n",
    "\n",
    "      # Step 6: Remove trailing sections like \"| Useful Links ...\" if present\n",
    "      '\\| Useful Links.*$', '', 'g'\n",
    "    )\n",
    "  ) AS text_data\n",
    "\n",
    "FROM locations;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out our work!\n",
    "locations_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql museum_transformed_df << SELECT text_data FROM locations_transformed_df WHERE location_id = 46;\n",
    "\n",
    "# We'll use a helper function \"wrap_print\" that I've implemented at the setup part of our tutorial\n",
    "wrap_print(museum_transformed_df.loc[0, \"text_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c2775",
   "metadata": {},
   "source": [
    "# 2. Customer Reviews\n",
    "\n",
    "In this part of our tutorial we'll implement some basic NLP techniques using only SQL on our customer reviews dataset.\n",
    "\n",
    "The following NLP techniques will be implemented:\n",
    "\n",
    "* Remove stopwords\n",
    "* Term Frequency\n",
    "* Document Frequency\n",
    "* TF-IDF\n",
    "\n",
    "We'll use our TF-IDF outputs to perform some simple search queries and to return most frequent terms in 5 star and 1 star reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfe53c",
   "metadata": {},
   "source": [
    "## 2.1 Inspect Reviews Data\n",
    "\n",
    "Let's first start with by inspecting our `reviews` table to see what data we have available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM reviews LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95553956",
   "metadata": {},
   "source": [
    "## 2.2 Data Transformations\n",
    "\n",
    "To prepare our reviews data for further NLP tasks and machine learning - we will implement the following transformations:\n",
    "\n",
    "1. Stopword removal\n",
    "2. Tokenize of uni-gram terms\n",
    "3. Term frequency\n",
    "4. Document frequency\n",
    "5. TF-IDF by combining term and document frequency\n",
    "\n",
    "We'll also apply a filter for just a single tour product `Coastal & Canyon Explorer` so we can easier see the differences in 1 and 5 star reviews within this sub-corpus or sub-collection of review documents.\n",
    "\n",
    "We can do this using SQL to mimic what might occur in a production database environment - however please note that most of the time we will use Python packages for their simplicity after extracting the required data from the database!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f5cc3",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1 Stopword Removal\n",
    "\n",
    "Normally in a Python based workflow - stop-word removal is accomplished using standard NLP library functions, however we don't have this luxury in most SQL databases including `DuckDB`.\n",
    "\n",
    "Luckily we can use our trusty `REGEXP_REPLACE` function to easily remove this huge list of English stop-words from our text data - these stop-words below are from the standard Python NLP library called `nltk`:\n",
    "\n",
    "```text\n",
    "a             about         above         after         again         ain  \n",
    "all           am            an            and           any           are  \n",
    "aren't        as            at            be            because       been  \n",
    "before        being         below         between       both          but  \n",
    "by            can           couldn        couldn't      d             did  \n",
    "didn't        didn          do            does          doesn't       doesn  \n",
    "doing         don't         don           down          during        each  \n",
    "few           for           from          further       had           hadn't  \n",
    "hadn          has           hasn't        hasn          have          haven't  \n",
    "haven         having        he            her           here          hers  \n",
    "herself       him           himself       his           how           i  \n",
    "if            in            into          is            isn't         isn  \n",
    "it            it's          its           itself        let's         ll  \n",
    "m             ma            me            mightn        mightn't      more  \n",
    "most          mustn         mustn't       my            myself        needn  \n",
    "needn't       no            nor           not           now           o  \n",
    "of            off           on            once          only          or  \n",
    "other         our           ours          ourselves     out           over  \n",
    "own           re            s             same          shan't        shan  \n",
    "she           she's         should        should've     shouldn't     shouldn  \n",
    "so            some          such          t             than          that  \n",
    "that'll       the           their         theirs        them          themselves  \n",
    "then          there         these         they          this          those  \n",
    "through       to            too           under         until         up  \n",
    "very          was           wasn't        wasn          we            were  \n",
    "weren't       weren         what          when          where         which  \n",
    "while         who           whom          why           will          with  \n",
    "won't         won           wouldn        wouldn't      y             you  \n",
    "you'd         you'll        you're        you've        your          yours  \n",
    "yourself      yourselves\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d1687",
   "metadata": {},
   "source": [
    "### 2.2.2 Tokenization\n",
    "\n",
    "We'll take a challenge to use only SQL to implement a basic form of text tokenization.\n",
    "\n",
    "The steps we'll use are as follows:\n",
    "\n",
    "1. Use `REGEXP_SPLIT_TO_ARRAY` to convert our text string into an array of \"terms\"\n",
    "2. Cross join onto an array from 1 to the `ARRAY_LENGTH` of our document to track \"position\"\n",
    "3. Slice our original document array of terms using our \"position\"\n",
    "\n",
    "Using this approach - we can also extend our analysis to generate bi-gram terms as a further challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5648d",
   "metadata": {},
   "source": [
    "### 2.2.3 Frequency Metrics\n",
    "\n",
    "Using our now tokenized data - we can use a simple `GROUP BY` clause on our `review_id` column with a `COUNT` function to generate the **term frequency** counts within each review. We can think of term frequency as \"how many times did this word appear in this review?\"\n",
    "\n",
    "For document frequency - we'll instead perform a `GROUP BY` on our terms and perform a `COUNT DISTINCT` on the `review_id` column. This helps us answer the question \"how many unique reviews included this specific word?\"\n",
    "\n",
    "Putting these two metrics together, we can generate one of the most common NLP metrics called `TF-IDF` or term frequency inverse document frequency.\n",
    "\n",
    "This helps us generate a metric for each term within each review so we can evaluate the following:\n",
    "\n",
    "1. How common is this term in the current review?\n",
    "2. How rare is this term across all reviews?\n",
    "\n",
    "We need to apply a natural log transformation to our value to scale our final output to account for large document counts.\n",
    "\n",
    "We'll attempt to implement TF-IDF as it appears in the Python `scikit-learn` library which includes a few smoothing components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba45f0",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.4 Mathematical Notation\n",
    "\n",
    "**Term Frequency (TF)**\n",
    "\n",
    "The term frequency of term *t* in document *d*:\n",
    "\n",
    "$$\n",
    "TF(t, d) = f_{t,d}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **f<sub>t,d</sub>**: the number of times term *t* appears in document *d*\n",
    "\n",
    "\n",
    "**Inverse Document Frequency (IDF)**\n",
    "\n",
    "The inverse document frequency of term *t* across the corpus:\n",
    "\n",
    "$$\n",
    "IDF(t) = \\log\\left( \\frac{1 + N}{1 + df(t)} \\right) + 1\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **N**: Total number of documents\n",
    "- **df(t)**: Number of documents that contain term *t*\n",
    "- Smoothing is applied by adding 1 in a few places to avoid division by zero and ensure numerical stability\n",
    "\n",
    "**TF-IDF Score**\n",
    "\n",
    "Combining both:\n",
    "\n",
    "$$\n",
    "TFIDF(t, d) = TF(t, d) \\times IDF(t)\n",
    "$$\n",
    "\n",
    "This score increases when a term is frequent in a specific document but rare across the entire collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82804e35",
   "metadata": {},
   "source": [
    "### 2.2.5 SQL Implementation\n",
    "\n",
    "Now let's take a look at how we can implement this end-to-end using SQL for all our transformations.\n",
    "\n",
    "We'll apply the following steps in the script below:\n",
    "\n",
    "1. Join `reviews` to `products` and apply filter to keep `Coastal & Canyon Explorer` tour product reviews\n",
    "2. Apply standard NLP cleaning steps on our `review_text` column in the following order:\n",
    "  1. Remove stop-words\n",
    "  2. Collapse multiple spaces into a single space\n",
    "  3. Remove punctuation using character class\n",
    "  4. Apply lowercase transformation\n",
    "  5. Trim leading and trailing whitespace\n",
    "3. Implement uni-gram terms tokenization\n",
    "4. Calculate term-frequency and document-frequency\n",
    "5. Combine both calculations to get TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_unigram_tfidf_df <<\n",
    "# ------------------------------------------------------\n",
    "# 1. Join reviews and products, apply NLP preprocessing\n",
    "# ------------------------------------------------------\n",
    "WITH cte_reviews AS (\n",
    "  SELECT\n",
    "    reviews.review_id,\n",
    "    products.product_name,\n",
    "    reviews.sentiment,\n",
    "    reviews.star_rating,\n",
    "\n",
    "    # Apply regex-based text normalization:\n",
    "    # Step 1: Remove stop-words\n",
    "    # Step 2: Collapse extra spaces\n",
    "    # Step 3: Remove punctuation\n",
    "    # Step 4: Lowercase text\n",
    "    # Step 5: Trim whitespace\n",
    "    TRIM(\n",
    "      LOWER(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              reviews.review_text,\n",
    "              '\\b(i|me|my|myself|...|wouldn''t)\\b', '', 'gi'\n",
    "            ),\n",
    "            '[\\s]+', ' ', 'g'\n",
    "          ),\n",
    "          '[\\(\\)''&,.:;\\\\‚Äî!]', '', 'g'\n",
    "        )\n",
    "      )\n",
    "    ) AS transformed_review_text\n",
    "\n",
    "  FROM reviews\n",
    "  INNER JOIN products ON reviews.product_id = products.product_id\n",
    "  WHERE products.product_name = 'Coastal & Canyon Explorer'\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Tokenize cleaned text into unigram terms\n",
    "# ------------------------------------------------------\n",
    "cte_arrays AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    REGEXP_SPLIT_TO_ARRAY(transformed_review_text, '\\s+') AS term_array\n",
    "  FROM cte_reviews\n",
    "),\n",
    "\n",
    "cte_range AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term_array,\n",
    "    i.unnest AS position\n",
    "  FROM cte_arrays\n",
    "  CROSS JOIN UNNEST(RANGE(1, ARRAY_LENGTH(term_array) + 1)) AS i\n",
    "),\n",
    "\n",
    "cte_tokenized AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term_array[position] AS term,\n",
    "    position\n",
    "  FROM cte_range\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3. Calculate term frequency (TF) and document frequency (DF)\n",
    "# ------------------------------------------------------\n",
    "cte_term_frequency AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "  FROM cte_tokenized\n",
    "  GROUP BY review_id, term\n",
    "),\n",
    "\n",
    "cte_document_frequency AS (\n",
    "  SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "  FROM cte_tokenized\n",
    "  GROUP BY term\n",
    "),\n",
    "\n",
    "cte_total_document_count AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT review_id) AS document_count\n",
    "  FROM cte_tokenized\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4. Combine stats and compute TF-IDF score\n",
    "# ------------------------------------------------------\n",
    "cte_combined AS (\n",
    "  SELECT\n",
    "    tf.review_id,\n",
    "    tf.term,\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    docs.document_count\n",
    "  FROM cte_term_frequency AS tf\n",
    "  LEFT JOIN cte_document_frequency AS df ON tf.term = df.term\n",
    "  CROSS JOIN cte_total_document_count AS docs\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5. Final output: TF-IDF scores with review metadata\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "  reviews.review_id,\n",
    "  reviews.product_name,\n",
    "  reviews.sentiment,\n",
    "  reviews.star_rating,\n",
    "  combined.term,\n",
    "  combined.term_frequency,\n",
    "  combined.document_frequency,\n",
    "\n",
    "  # TF-IDF formula: tf * log-scaled inverse document frequency\n",
    "  combined.term_frequency * (\n",
    "    LN((1 + combined.document_count) / (1 + combined.document_frequency)) + 1\n",
    "  ) AS tfidf\n",
    "\n",
    "FROM cte_combined AS combined\n",
    "LEFT JOIN cte_reviews AS reviews ON combined.review_id = reviews.review_id\n",
    "ORDER BY reviews.review_id, tfidf DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ec0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Let's just take a look at our very first review_id we were inspecting before\n",
    "%sql SELECT * FROM reviews_unigram_tfidf_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995d351",
   "metadata": {},
   "source": [
    "## 2.3 TF-IDF Questions\n",
    "\n",
    "Let's apply some aggregations to our TF-IDF metrics for uni-gram terms and ask a few simple questions of our Coastal & Canyon Explorer reviews data.\n",
    "\n",
    "1. Which are the highest TF-IDF terms for all 1 star reviews?\n",
    "2. Which are the highest TF-IDF terms for all 5 star reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6764cf4",
   "metadata": {},
   "source": [
    "### 2.3.1 1 Star Reviews\n",
    "\n",
    "> Which are the highest TF-IDF terms for all 1 star reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a228ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  term,\n",
    "  AVG(tfidf) AS avg_tfidf\n",
    "FROM reviews_unigram_tfidf_df\n",
    "WHERE star_rating = 1\n",
    "GROUP BY term\n",
    "ORDER BY avg_tfidf DESC\n",
    "LIMIT 25;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb906ed",
   "metadata": {},
   "source": [
    "### 2.3.2 5 Star Reviews\n",
    "\n",
    "> Which are the highest TF-IDF terms for all 5 star reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69174494",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  term,\n",
    "  AVG(tfidf) AS avg_tfidf\n",
    "FROM reviews_unigram_tfidf_df\n",
    "WHERE star_rating = 5\n",
    "GROUP BY term\n",
    "ORDER BY avg_tfidf DESC\n",
    "LIMIT 25;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceaddae",
   "metadata": {},
   "source": [
    "## 2.4 Comparing Bigram Outputs\n",
    "\n",
    "We can alter our query just slightly to generate the same TF-IDF analysis but this time using bi-gram terms instead of uni-gram terms to provide more context as we analyze the NLP outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf389c",
   "metadata": {},
   "source": [
    "### 2.4.1 SQL Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697757ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql reviews_bigram_tfidf_df <<\n",
    "# ------------------------------------------------------\n",
    "# 1. Join reviews and products, apply NLP text cleaning\n",
    "# ------------------------------------------------------\n",
    "WITH cte_reviews AS (\n",
    "  SELECT\n",
    "    reviews.review_id,\n",
    "    products.product_name,\n",
    "    reviews.sentiment,\n",
    "    reviews.star_rating,\n",
    "\n",
    "    # Apply stop-word removal, punctuation cleanup, lowercasing, whitespace trim\n",
    "    TRIM(\n",
    "      LOWER(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              reviews.review_text,\n",
    "              '\\b(i|me|my|myself|we|our|...|wouldn''t)\\b', '', 'gi'       # Step 1: Remove stop words\n",
    "            ),\n",
    "            '[\\s]+', ' ', 'g'                                             # Step 2: Collapse spaces\n",
    "          ),\n",
    "          '[\\(\\)''&,.:;\\\\‚Äî!]', '', 'g'                                    # Step 3: Remove punctuation\n",
    "        )\n",
    "      )\n",
    "    ) AS transformed_review_text\n",
    "  FROM reviews\n",
    "  INNER JOIN products ON reviews.product_id = products.product_id\n",
    "  WHERE products.product_name = 'Coastal & Canyon Explorer'\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Tokenize into arrays for bi-gram generation\n",
    "# ------------------------------------------------------\n",
    "cte_arrays AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    REGEXP_SPLIT_TO_ARRAY(transformed_review_text, '\\s+') AS term_array\n",
    "  FROM cte_reviews\n",
    "),\n",
    "\n",
    "cte_range AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term_array,\n",
    "    i.unnest AS position\n",
    "  FROM cte_arrays\n",
    "  CROSS JOIN UNNEST(RANGE(1, ARRAY_LENGTH(term_array) + 1)) AS i         # Map positions 1..N\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3. Extract bi-gram terms using LAG\n",
    "# ------------------------------------------------------\n",
    "cte_tokenized_base AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term_array[position] AS unigram_term,\n",
    "    position\n",
    "  FROM cte_range\n",
    "),\n",
    "\n",
    "cte_tokenized AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    LAG(unigram_term) OVER (PARTITION BY review_id ORDER BY position) || ' ' || unigram_term AS term\n",
    "  FROM cte_tokenized_base\n",
    "  QUALIFY term IS NOT NULL\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4. Compute term frequency (TF) and document frequency (DF)\n",
    "# ------------------------------------------------------\n",
    "cte_term_frequency AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    term,\n",
    "    COUNT(*) AS term_frequency\n",
    "  FROM cte_tokenized\n",
    "  GROUP BY review_id, term\n",
    "),\n",
    "\n",
    "cte_document_frequency AS (\n",
    "  SELECT\n",
    "    term,\n",
    "    COUNT(DISTINCT review_id) AS document_frequency\n",
    "  FROM cte_tokenized\n",
    "  GROUP BY term\n",
    "),\n",
    "\n",
    "cte_total_document_count AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT review_id) AS document_count\n",
    "  FROM cte_tokenized\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5. Combine stats and compute TF-IDF score\n",
    "# ------------------------------------------------------\n",
    "cte_combined AS (\n",
    "  SELECT\n",
    "    tf.review_id,\n",
    "    tf.term,\n",
    "    COALESCE(tf.term_frequency, 0) AS term_frequency,\n",
    "    COALESCE(df.document_frequency, 0) AS document_frequency,\n",
    "    docs.document_count\n",
    "  FROM cte_term_frequency AS tf\n",
    "  LEFT JOIN cte_document_frequency AS df ON tf.term = df.term\n",
    "  CROSS JOIN cte_total_document_count AS docs\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6. Final output with review metadata and sorted TF-IDF\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "  reviews.review_id,\n",
    "  reviews.product_name,\n",
    "  reviews.sentiment,\n",
    "  reviews.star_rating,\n",
    "  combined.term,\n",
    "  combined.term_frequency,\n",
    "  combined.document_frequency,\n",
    "\n",
    "  # TF-IDF scoring formula\n",
    "  combined.term_frequency * (\n",
    "    LN((1 + combined.document_count) / (1 + combined.document_frequency)) + 1\n",
    "  ) AS tfidf\n",
    "\n",
    "FROM cte_combined AS combined\n",
    "LEFT JOIN cte_reviews AS reviews ON combined.review_id = reviews.review_id\n",
    "ORDER BY reviews.review_id, tfidf DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first review ID to see the difference\n",
    "%sql SELECT * FROM reviews_bigram_tfidf_df WHERE review_id = '000319b1';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e46f0f",
   "metadata": {},
   "source": [
    "### 2.4.1 1 Star Reviews\n",
    "\n",
    "> Which are the highest TF-IDF bi-gram terms for all 1 star reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  term,\n",
    "  AVG(tfidf) AS avg_tfidf\n",
    "FROM reviews_bigram_tfidf_df\n",
    "WHERE star_rating = 1\n",
    "GROUP BY term\n",
    "ORDER BY avg_tfidf DESC\n",
    "LIMIT 25;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaafbc5",
   "metadata": {},
   "source": [
    "### 2.4.2 5 Star Reviews\n",
    "\n",
    "> Which are the highest TF-IDF bi-gram terms for all 5 star reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d810dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "  term,\n",
    "  AVG(tfidf) AS avg_tfidf\n",
    "FROM reviews_bigram_tfidf_df\n",
    "WHERE star_rating = 5\n",
    "GROUP BY term\n",
    "ORDER BY avg_tfidf DESC\n",
    "LIMIT 25;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Pandas option to only show top 10 rows\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc3bf9",
   "metadata": {},
   "source": [
    "# 3. Implement A/B Framework\n",
    "\n",
    "The final part of our NLP challenge is to design a measurement framework to quantify the uplift of an AI experiment.\n",
    "\n",
    "In our Explore California business example - an NLP search experiment was conducted in the first 3 months of 2026. 50% of the website visitors are exposed to an AI powered \"NLP search\" tool while the remaining 50% see the original experience.\n",
    "\n",
    "Let's explore the SQL implementation to compare the two groups of website visitors and apply some statistical testing to validate whether the new NLP search lead to a significant uplift in product sales for the experiment period.\n",
    "\n",
    "To help us with our table joins - we can inspect the entity relationship diagram below.\n",
    "\n",
    "<iframe width=\"100%\" height=\"600\" src='https://dbdiagram.io/e/685279b3f039ec6d36c0c7e9/68527d19f039ec6d36c1813e'> </iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e92d8",
   "metadata": {},
   "source": [
    "## 3.1 Inspect Raw Data\n",
    "\n",
    "We can begin by taking a look at the `sales`, `visits` and `features` tables - these will be key to our analysis!\n",
    "\n",
    "For our `features` - we'll apply a filter for \"Search\" for our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM sales LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM visits LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aca04a",
   "metadata": {},
   "source": [
    "And finally - we've got a `features` table which identifies the `visit_id` values where an AI powered feature was shown.\n",
    "\n",
    "For our first NLP search feature - we can apply a filter on this table for \"Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84265eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM features\n",
    "WHERE feature = 'Search'\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19201f3",
   "metadata": {},
   "source": [
    "## 3.2 Experimental Analysis Base\n",
    "\n",
    "Let's have a go at combining all of these tables to generate a single table where we can apply all of our analysis.\n",
    "\n",
    "The required columns that we'll need for this table are below:\n",
    "\n",
    "* visit_timestamp\n",
    "* visit_id\n",
    "* user_id\n",
    "* feature_flag (if it exists)\n",
    "* sale_flag (if it exists)\n",
    "* sale_amount (use the `products` table to find the USD price)\n",
    "\n",
    "Let's also filter this table to only include the first 3 months of 2026 - this is when our theoretical AI experiment is running.\n",
    "\n",
    "We will store out outputs as `experiment_analysis_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql experiment_analysis_df <<\n",
    "# ------------------------------------------------------\n",
    "# 1. Join visits with feature flags, sales, and product data\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "  visits.visit_timestamp,\n",
    "  visits.visit_id,\n",
    "  visits.user_id,\n",
    "\n",
    "  # Flag whether the feature was active for this visit\n",
    "  CASE \n",
    "    WHEN features.feature IS NOT NULL THEN 1 \n",
    "    ELSE 0 \n",
    "  END AS feature_flag,\n",
    "\n",
    "  # Flag whether a sale occurred during this visit\n",
    "  CASE \n",
    "    WHEN sales.sale_id IS NOT NULL THEN 1 \n",
    "    ELSE 0 \n",
    "  END AS sale_flag,\n",
    "\n",
    "  # Capture sale amount; default to 0 if no product linked\n",
    "  COALESCE(products.price_usd, 0) AS sale_amount\n",
    "\n",
    "FROM visits\n",
    "\n",
    "# Join feature exposure data (optional per visit)\n",
    "LEFT JOIN features \n",
    "  ON visits.visit_id = features.visit_id\n",
    "\n",
    "# Join sales data (optional per visit)\n",
    "LEFT JOIN sales \n",
    "  ON visits.visit_id = sales.visit_id\n",
    "\n",
    "# Join product price info (optional if sale exists)\n",
    "LEFT JOIN products \n",
    "  ON sales.product_id = products.product_id\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Filter to experiment window: Q1 2026\n",
    "# ------------------------------------------------------\n",
    "WHERE visits.visit_timestamp BETWEEN DATE '2026-01-01' AND DATE '2026-03-31';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5344e",
   "metadata": {},
   "source": [
    "## 3.3 Split Group Comparison\n",
    "\n",
    "We can use our table `experiment_analysis_df` to answer a few relevant questions by splitting up our visits based on the `feature_flag`:\n",
    "\n",
    "1. How many sales are there and what is the total sale amount?\n",
    "2. What is the total number of visits for the 3 month period?\n",
    "3. What percentage of visits lead to a sale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "# ------------------------------------------------------\n",
    "# 1. Aggregate conversion and revenue metrics by feature group\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "  feature_flag,  # 0 = control group, 1 = treatment group\n",
    "\n",
    "  # Count of unique visits that resulted in a sale\n",
    "  COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS sales_count,\n",
    "\n",
    "  # Total dollar value of all sales\n",
    "  SUM(sale_amount) AS sales_amount,\n",
    "\n",
    "  # Total number of visits in each group\n",
    "  COUNT(DISTINCT visit_id) AS visit_count,\n",
    "\n",
    "  # Conversion rate = sales / total visits\n",
    "  sales_count / visit_count AS conversion_rate\n",
    "\n",
    "FROM experiment_analysis_df\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Group by control vs treatment and sort by flag\n",
    "# ------------------------------------------------------\n",
    "GROUP BY feature_flag\n",
    "ORDER BY feature_flag;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ab7ba",
   "metadata": {},
   "source": [
    "## 3.4 Hypothesis Testing\n",
    "\n",
    "In A/B testing scenarios like this, we often want to know whether one group (e.g., a new feature group or \"target\") performs better than another group (e.g., the \"control\").\n",
    "\n",
    "Since we are specifically interested in whether the **target group performs better**, we use a **one-tailed test** ‚Äî focusing only on **positive uplift**. A one-tailed test checks whether the target group‚Äôs conversion rate is significantly **higher** than the control group‚Äôs, not just different.\n",
    "\n",
    "This is different from a **two-tailed test**, which checks for **any difference** ‚Äî either higher or lower ‚Äî without considering direction. One-tailed tests are more powerful when directionality is relevant, but should only be used when you're confident about the expected direction.\n",
    "\n",
    "We set our **alpha level** at `0.05`, which means we accept up to a 5% chance of a false positive ‚Äî rejecting the null hypothesis when there is no true difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53d106",
   "metadata": {},
   "source": [
    "### 3.4.1 Z-Score Formula\n",
    "\n",
    "The **z-score** is a statistical measure that tells us how unusual or extreme the observed difference in conversion rates is, assuming the null hypothesis (no difference) is true.\n",
    "\n",
    "In our case, we want a high z-score to **disprove the null hypothesis** that the target group performs the same as the control group.\n",
    "\n",
    "The z-score for the difference in proportions is calculated as:\n",
    "\n",
    "$$\n",
    "z = \\frac{p_1 - p_2}{\\sqrt{p(1 - p) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $p_1 = \\dfrac{x_1}{n_1}$ ‚Äî Target group conversion rate  \n",
    "- $p_2 = \\dfrac{x_2}{n_2}$ ‚Äî Control group conversion rate\n",
    "- $p = \\dfrac{x_1 + x_2}{n_1 + n_2}$ ‚Äî Overall conversion rate\n",
    "- $x_1$, $x_2$ ‚Äî number of sales in each target and control group  \n",
    "- $n_1$, $n_2$ ‚Äî number of visits/observations in each target and control group\n",
    "\n",
    "A z-score above **1.645** indicates statistical significance at the 95% confidence level for a **one-tailed** test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f74a5b",
   "metadata": {},
   "source": [
    "\n",
    "### 3.4.2  Standard Error of Target Conversion Rate\n",
    "\n",
    "To measure the uncertainty of the **target group and control group conversion rates**, we use the standard error of a single proportion:\n",
    "\n",
    "$$\n",
    "SE_{p_1} = \\sqrt{ \\frac{p_1(1 - p_1)}{n_1} }\n",
    "$$\n",
    "\n",
    "This allows us to construct a confidence interval around the conversion rates independently.\n",
    "\n",
    "$$\n",
    "CI_{p_1} = p_1 \\pm Z \\cdot SE_{p_1}\n",
    "$$\n",
    "\n",
    "For example, using \\( Z = 1.96 \\) gives a 95% confidence interval.\n",
    "\n",
    "### 3.4.3 Standard Error of Uplift (Difference in Proportions)\n",
    "\n",
    "To calculate a confidence interval for the **uplift** ‚Äî the difference in conversion rates between the target and control groups ‚Äî we use the following:\n",
    "\n",
    "$$\n",
    "SE_{\\text{uplift}} = \\sqrt{ \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2} }\n",
    "$$\n",
    "\n",
    "Then the confidence interval for the uplift becomes:\n",
    "\n",
    "$$\n",
    "CI_{\\text{uplift}} = (p_1 - p_2) \\pm 1.96 \\cdot SE_{\\text{uplift}}\n",
    "$$\n",
    "\n",
    "This gives us a plausible range for the **true uplift**, helping us assess not just whether the result is statistically significant, but also how **meaningful** it might be.\n",
    "\n",
    "By combining z-score testing and confidence intervals, we get a more complete picture of both **statistical significance** and **practical impact**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a121d",
   "metadata": {},
   "source": [
    "## 3.5 SQL Implementation\n",
    "\n",
    "### üìà What This SQL Code Does\n",
    "\n",
    "This SQL workflow evaluates the impact of a feature rollout using an A/B test framework ‚Äî comparing a **target group** (with the feature enabled) against a **control group** (feature off).\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Step-by-Step Breakdown\n",
    "\n",
    "1. **Aggregate Metrics for Control Group**  \n",
    "   Calculates the number of visits, conversions (sales), total revenue, and overall conversion rate for users **without** the feature (`feature_flag = 0`).\n",
    "\n",
    "2. **Aggregate Metrics for Target Group**  \n",
    "   Does the same calculations for users **with** the feature (`feature_flag = 1`).\n",
    "\n",
    "3. **Combine Groups**  \n",
    "   Joins control and target group results into a single row for side-by-side comparison.\n",
    "\n",
    "4. **Calculate Uplift & Confidence Intervals**  \n",
    "   - Computes the **absolute uplift** in conversion rate between the two groups  \n",
    "   - Calculates 95% confidence intervals for both conversion rates  \n",
    "   - Computes the **standard error** of the uplift to prepare for statistical testing\n",
    "\n",
    "5. **Run Significance Test & Estimate Business Impact**  \n",
    "   - Calculates a **z-score** to test statistical significance  \n",
    "   - Flags the result as ‚ÄúSignificant‚Äù or ‚ÄúNot Significant‚Äù using a one-tailed 95% test  \n",
    "   - Estimates the number of **incremental sales**  \n",
    "   - Projects **baseline revenue** (what the target group would have earned without the uplift)  \n",
    "   - Calculates **incremental revenue** driven by the feature\n",
    "\n",
    "6. **Return Final Results**  \n",
    "   Outputs all the key metrics: uplift, significance, confidence intervals, and business impact ‚Äî giving a complete picture of how effective the feature was.\n",
    "\n",
    "---\n",
    "\n",
    "This analysis helps us make **data-driven decisions** about whether a new product feature led to meaningful improvement in user behavior and business outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql experiment_results_df <<\n",
    "# ------------------------------------------------------\n",
    "# 1. Aggregate control group metrics\n",
    "# ------------------------------------------------------\n",
    "WITH cte_control AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT visit_id) AS control_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS control_sales_count,\n",
    "    SUM(sale_amount) AS control_sales_amount,\n",
    "    control_sales_count / control_visit_count AS control_conversion_rate\n",
    "  FROM experiment_analysis_df\n",
    "  WHERE feature_flag = 0\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Aggregate target group metrics\n",
    "# ------------------------------------------------------\n",
    "cte_target AS (\n",
    "  SELECT\n",
    "    COUNT(DISTINCT visit_id) AS target_visit_count,\n",
    "    COUNT(DISTINCT CASE WHEN sale_flag = 1 THEN visit_id ELSE NULL END) AS target_sales_count,\n",
    "    SUM(sale_amount) AS target_sales_amount,\n",
    "    target_sales_count / target_visit_count AS target_conversion_rate\n",
    "  FROM experiment_analysis_df\n",
    "  WHERE feature_flag = 1\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3. Combine control and target groups into a single row\n",
    "# ------------------------------------------------------\n",
    "cte_combined AS (\n",
    "  SELECT\n",
    "    control.*,\n",
    "    target.*\n",
    "  FROM cte_target AS target\n",
    "  CROSS JOIN cte_control AS control\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4. Calculate uplift and confidence intervals\n",
    "# ------------------------------------------------------\n",
    "cte_stats AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    \n",
    "    # Absolute uplift in conversion rate\n",
    "    target_conversion_rate - control_conversion_rate AS absolute_uplift,\n",
    "\n",
    "    # 95% Confidence Interval for target group conversion rate\n",
    "    target_conversion_rate - 1.96 * SQRT((target_conversion_rate * (1 - target_conversion_rate)) / target_visit_count) AS target_ci_lower,\n",
    "    target_conversion_rate + 1.96 * SQRT((target_conversion_rate * (1 - target_conversion_rate)) / target_visit_count) AS target_ci_upper,\n",
    "\n",
    "    # 95% Confidence Interval for control group conversion rate\n",
    "    control_conversion_rate - 1.96 * SQRT((control_conversion_rate * (1 - control_conversion_rate)) / control_visit_count) AS control_ci_lower,\n",
    "    control_conversion_rate + 1.96 * SQRT((control_conversion_rate * (1 - control_conversion_rate)) / control_visit_count) AS control_ci_upper,\n",
    "\n",
    "    # Standard error for difference in conversion rates\n",
    "    SQRT(\n",
    "      (target_conversion_rate * (1 - target_conversion_rate)) / target_visit_count +\n",
    "      (control_conversion_rate * (1 - control_conversion_rate)) / control_visit_count\n",
    "    ) AS uplift_se\n",
    "  FROM cte_combined\n",
    "),\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5. Calculate z-score, test result, and revenue impact\n",
    "# ------------------------------------------------------\n",
    "cte_zscore AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    \n",
    "    # Z-score for difference in proportions\n",
    "    absolute_uplift / uplift_se AS z_score,\n",
    "\n",
    "    # Test result: one-tailed 95% significance test\n",
    "    CASE \n",
    "      WHEN absolute_uplift / uplift_se >= 1.645 THEN 'Significant'\n",
    "      ELSE 'Not Significant'\n",
    "    END AS test_result,\n",
    "\n",
    "    # 95% Confidence Interval for absolute uplift\n",
    "    absolute_uplift - 1.96 * uplift_se AS uplift_ci_lower,\n",
    "    absolute_uplift + 1.96 * uplift_se AS uplift_ci_upper,\n",
    "\n",
    "    # Estimated incremental conversions\n",
    "    target_visit_count * absolute_uplift AS incremental_sales_count,\n",
    "\n",
    "    # Expected sales amount if no uplift had occurred (baseline projection)\n",
    "    control_conversion_rate * target_visit_count * \n",
    "      (control_sales_amount * 1.0 / NULLIF(control_sales_count, 0)) AS expected_sales_amount_without_uplift,\n",
    "\n",
    "    # Difference in observed sales revenue between target and control groups\n",
    "    target_sales_amount - control_sales_amount AS incremental_sales_amount\n",
    "  FROM cte_stats\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6. Final output: summarized experiment evaluation\n",
    "# ------------------------------------------------------\n",
    "SELECT\n",
    "\n",
    "  # Statistical Test Results\n",
    "  z_score,\n",
    "  test_result,\n",
    "\n",
    "  # Uplift and Impact Metrics\n",
    "  absolute_uplift,\n",
    "  uplift_ci_lower,\n",
    "  uplift_ci_upper,\n",
    "  incremental_sales_count,\n",
    "  incremental_sales_amount,\n",
    "\n",
    "  # Target Group Metrics\n",
    "  target_visit_count,\n",
    "  target_sales_count,\n",
    "  target_conversion_rate,\n",
    "  target_ci_lower,\n",
    "  target_ci_upper,\n",
    "\n",
    "  # Control Group Metrics\n",
    "  control_visit_count,\n",
    "  control_sales_count,\n",
    "  control_conversion_rate,\n",
    "  control_ci_lower,\n",
    "  control_ci_upper\n",
    "\n",
    "FROM cte_zscore;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefeb4c",
   "metadata": {},
   "source": [
    "## 3.6 Experimentation Insights\n",
    "\n",
    "Here is an example report we can generate using our calculated metrics from our A/B test framework.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Experiment Results Summary\n",
    "\n",
    "Our A/B test aimed to evaluate whether the new NLP search feature (enabled in the **target** group) led to improved conversion and revenue performance compared to the control group.\n",
    "\n",
    "#### ‚úÖ Statistical Significance\n",
    "\n",
    "- **Z-score**: `13.63`  \n",
    "- **Result**: **Significant** at the 95% confidence level (one-tailed test)\n",
    "\n",
    "This indicates **strong evidence** that the target group outperformed the control group in conversion rate.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Conversion Performance\n",
    "\n",
    "| Metric                     | Control Group  | Target Group     |\n",
    "|----------------------------|----------------|------------------|\n",
    "| Number of Visits           | 24,336         | 24,355           |\n",
    "| Number of Conversions      | 1,700          | 2,549            |\n",
    "| Conversion Rate            | 6.99%          | 10.47%           |\n",
    "| 95% CI (Conversion Rate)   | [6.67%, 7.31%] | [10.08%, 10.85%] |\n",
    "\n",
    "- **Absolute uplift in conversion rate**: **+3.48%**  \n",
    "- **95% Confidence Interval for uplift**: [2.98%, 3.98%]\n",
    "\n",
    "---\n",
    "\n",
    "#### üí∞ Revenue Impact\n",
    "\n",
    "- **Estimated incremental conversions**: `~848` additional sales  \n",
    "- **Incremental sales amount**: **$2,166,053**\n",
    "\n",
    "This represents the **additional revenue** generated by the target group over what we would have expected had they performed like the control group ‚Äî while accounting for variation in sale amounts per product.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Conclusion\n",
    "\n",
    "The experiment showed a **statistically significant uplift** in both conversion rate and revenue. Based on the observed metrics, enabling the new NLP search feature is likely to drive meaningful business impact through increased sales and revenue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
